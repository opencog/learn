#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{url} 
\usepackage{slashed}
\end_preamble
\use_default_options false
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "times" "default"
\font_sans "helvet" "default"
\font_typewriter "cmtt" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\listings_params "basicstyle={\ttfamily},basewidth={0.45em}"
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Title
Diary – Part Ten–F
\end_layout

\begin_layout Date
October 2025 – present
\end_layout

\begin_layout Author
Linas Vepštas
\end_layout

\begin_layout Abstract
Unlike parts one through nine in this series,
 this one is not really about the language–learning effort.
 It is instead a private diary;
 a continuation of Part Ten–E,
 which got over–long.
 It is not curated for human consumption;
 I am making the assumption that no human being will ever actually read this.
 Thus,
 it is filled with random stuff I feel like writing.
 Some of it is very personal,
 some of it is nonsense.
 Mostly,
 I am finding that the act of writing helps otherwise vague and scattered thoughts quantum–collapse into a more coherent form,
 where I can examine them,
 like a dead butterfly pinned down in a display case.
 Dead words.
\end_layout

\begin_layout Abstract
If you are interested in this content,
 then you should ask an AI agent to read it,
 then pretended that it's me,
 then ask about it.
 I believe that present–day LLM technology is sufficiently advanced to be able to do this.
 
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Part Ten already got an introduction.
 A different way of thinking is about what is going on here is that this is a form of life–logging.
 Or,
 in 18th century terms,
 a diary.
 Just not anywhere near as compelling as those written by the famous diarists.
 This one is more of a mental self–portrait.
 And not even for you but for myself.
 Not to cast a narcissistic gaze at my own words,
 but to organize my own thoughts.
 Still in the experimental stage.
\end_layout

\begin_layout Subsection*
23 October 2025
\end_layout

\begin_layout Standard
I posted a long reply to bluesky that I rather like,
 so I am copying it here.
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
· 3h
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
apologies for being subjected to my shower thoughts ,
 has anyone tried to do physics sims with atomspace ala gravitas method that wolfram alpha tried ?
 
\end_layout

\begin_layout Standard
wolframinstitute.org/output/compu...
\end_layout

\begin_layout Standard
i *may* have already asked you this ,
 apologies for any memory loss (it's accelarating)
\end_layout

\begin_layout Standard
Computational General Relativity in the Wolfram Language using Gravitas I:
 Symbolic and Analytic Computation —
 Wolfram Institute
\end_layout

\begin_layout Standard
Jonathan Gorard Gravitas introduces a robust computational framework for general relativity in the Wolfram Language,
 featuring seamless integration of symbolic and numerical tools to handle complex ...
\end_layout

\begin_layout Standard
wolframinstitute.org
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1h
\end_layout

\begin_layout Standard
No one has tried.
 But its a good question.
 I want to tell you what I want to do with the Atomspace for this kind of stuff,
 and also a guess at what wolfram is actually doing.
 Perhaps a guess a about wolfram,
 first.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1h
\end_layout

\begin_layout Standard
So,
 there's a giant industry for solving diffeqs.
 The most famous of these are weather prediction,
 and then fluid dynamics for wings,
 boats,
 sails,
 jet engines,
 rocket exhaust,
 and them mechanical stress,
 vibration,
 safety.
 Some run on supercomputers,
 others on ordinary PCs.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1h
\end_layout

\begin_layout Standard
Solving GR equations is a very special case.
 Due to history,
 this is usually runs on supercomputers,
 FORTRAN code written by grad students of the decades.
 My grad school office-mate was blowing up supernova on Los Alamos machines.
 So,
 atomic bombs,
 but much much bigger.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 57m
\end_layout

\begin_layout Standard
The gravitational wave search code will also be running on supercomputers with gobs of GPU's on each node,
 using code that has been tuned,
 revised,
 rewritten,
 again and again over the decades.
 Works great,
 if you have the money,
 the NSF grants needed to get supercomputer access.
 But ...
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 55m
\end_layout

\begin_layout Standard
What happens if you're a starting grad student and your thesis advisor is a shmuck with no grants,
 and you want to dabble in this?
 Wolfram is providing a rather awesomely appetizing solution:
 something you can mess with easily and at low cost.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 52m
\end_layout

\begin_layout Standard
I assume Wolfram's code is written by an LLM,
 Claude or ChatGPT,
 so trained on that supercomputer code,
 "likely to be correct".
 I assume its overseen by a "professional software engineer" (grad students and their profs write amazingly shitty code.
 Paying a real developer works wonders.)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 50m
\end_layout

\begin_layout Standard
So,
 having some professionally-written GR-solving code that runs on your laptop,
 and/or some mid-range monster machine you can afford,
 integrated with the rest of the wolfram stack...
 this is a winner.
 All that's losing about it is it's not open source and is a walking GPL violation.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 42m
\end_layout

\begin_layout Standard
And now,
 for opencog.
 I'm interesting in something similar,
 but different.
 The starting point,
 for me,
 are concepts from proof theory.
 In proof theory,
 you have a collection of axioms,
 and a collection of inference rules.
 These have the form of "jigsaw pieces",
 and ...
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 37m
\end_layout

\begin_layout Standard
By assembling and reassembling these,
 one can ..
 construct proofs ...
 simplify equations ...
 make inferences ...
 generate hypothesis ...
 solve constraint problems ...
 optimize solutions ...
 This is a vast collection of comp-sci tasks for which there are thousands of very custom algos for solving.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 32m
\end_layout

\begin_layout Standard
I want to unify these into a general framework.
 e.g.
 there are many constraint solvers;
 my favorite is the UPotsdam ASP solver.
 There are many theorem provers,
 I have no favorite.
 For general symbolc algebra systems,
 we have wolfram and symbolica,
 octave,
 maxima,
 sympy,
 ....
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 30m
\end_layout

\begin_layout Standard
Examples of optimizers include the internals of gcc and clang:
 systems that take algebraic expressions (written in C/C++/Java),
 compile them into some intermediate language,
 optimize,
 then compile to assembly or bytecode or JIT.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
But you could never use compiler internals to "prove math theorems in general",
 and maybe in principle you could use a theorem provide to implement a compiler it would be dog-shit slow.
 Neither replaces maxima/symbolic/whatever.
 None are as fast as a SAT solver.
\end_layout

\begin_layout Standard
October 23,
 2025 at 5:25 PM
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 25m
\end_layout

\begin_layout Standard
So I'm interested in the generic problem of assembling jigsaw pieces.
 Which,
 BTW,
 is called "parsing" and "generation" in traditional comp sci.
 Which,
 unfortunately,
 obscures the depth of breadth of what "parsing" or "generation" actually are.
 Those two words erect a mental prison.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 21m
\end_layout

\begin_layout Standard
Getting back to general relativity:
 there is one more step,
 taken by Przemysław Prusinkiewiwcz,
 in "Algorithmic Botany".
 He takes cellular automata (think "DNA") and couples them to diff-eq (think "biochemical reactions") and low and behold,
 can explain "most of" botany.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 18m
\end_layout

\begin_layout Standard
It's the most utterly remarkable work I've ever seen,
 I'm not sure why he doesn't have a Nobel Prize.
 To me,
 it feels like its foundational for the so-called "neuro-symbolic computing" that is all the rage these days.
 Except the DL/NN folks don't give two figs for botany,
 so ...
 well,
 you know.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 14m
\end_layout

\begin_layout Standard
Side remark:
 the Michael Levin stuff about embedded cognition:
 they way I think about it is that one has these "jigsaws" floating around in a medium,
 e.g.
 enzymes.
 Or DNA.
 Or perhaps very abstractly:
 cell walls,
 or larger organs,
 growths,
 limbs.
 And these jigsaws self-assemble.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 10m
\end_layout

\begin_layout Standard
So I want my jigsaws to self-assemble also.
 But abstractly.
 My jigsaws can be axioms and inference rules.
 Or they can be 3D biochemical molecules.
 Or they can be immunoglobulin.
 Or a mycelial mat.
 Or ...
 optimization problems from economics (the barley and malt optimization problem from brewing.)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 7m
\end_layout

\begin_layout Standard
I don't care ..
 all these problems fall into the same class,
 all can be ruled by a generic theory.
 Fast algorithms in one problem domain can be homotopically transformed into fast algorithms in other problem domains.
 And we've got enough homotopy type theory with which to do this ...
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4m
\end_layout

\begin_layout Standard
But building the actual infrastructure to do this:
 sheesh.
 It's damn near impossible.
 I'm like ...
 boiling the ocean.
 No one nowhere has any kind of generic,
 general purpose codes for any of this.
 So I'm hand-sculpting it with a pocket knife from a piece of balsa wood...
 Oof.
 What else can I do?
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
quick side note ,
 this guy is the one that did most of the research afaik (wolfram classic :
 taking others credit) 
\end_layout

\begin_layout Standard
nitter.net/getjonwithit <-- non twitter twitter link ,
 i dont have twitter and never will
\end_layout

\begin_layout Standard
October 23,
 2025 at 4:51 PM
\end_layout

\begin_layout Standard
1 like
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 41s
\end_layout

\begin_layout Standard
Ehh!
 The diagrams at the top of that page are instantly recognizable to be as being from "ChemLambda" from Marius Buliga its ...
 actually quite fascinating,
 and is an example of "jigsaw self-assembly".
 He's using lambda calc as the theoretical foundation,
 I'm trying to use sheaves.
 But that's OK.
\end_layout

\begin_layout Standard
—
—
—
-
\end_layout

\begin_layout Standard
Then I wrote this,
 but its kind of boring old–hat old–news (to me)
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
· 2h
\end_layout

\begin_layout Standard
do you have thoughts on how classical mechanics erupt from probabilistic quantum mechanics ?
 more exactly why are there what seems like thresholds of complexity where these emerge ?
 one of the issues with most of these computational approaches is the intractability of ground up computing
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
· 2h
\end_layout

\begin_layout Standard
you need those coarse grained "compressed" heuristics (classical neutonian / general relativitiy) to do the computation at all ..
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1h
\end_layout

\begin_layout Standard
?
 Almost all GR calculations are "classical".
 See for example,
 "Relativistic Cosmology" (Ellis Maartens MacCullum) for how to do (some of) these (yes,
 I read the first 1/3rd of that book.
 Plan was to get to MOND but haven't yet...)..
 there are many texts on what to do and how to do it.
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
by classical i was distinguishing quantum mechanics from neutonian / gr / sr 
\end_layout

\begin_layout Standard
for instance the more environmental interaction any set of atoms will start to decohere to the point where they start acting classically ..
 because information can only travel at the speed of light gr can emerge from
\end_layout

\begin_layout Standard
October 23,
 2025 at 6:12 PM
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 25m
\end_layout

\begin_layout Standard
Newtonian.
 Think of QM as being a Gaussian,
 then classical physics is the expectation value of that gaussian.
 Its that one very special value.
 I mean this in a very literal sense,
 the one that is used in "stationary phase approximation" or "principle of least action".
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 23m
\end_layout

\begin_layout Standard
An elegant example is found in Riemannian geometry.
 Think of e.g.
 some surface,
 and "all possible paths" from point A to point B.
 What's the "shortest possible path from A to B?" (aka "what's the geodesic"?)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 20m
\end_layout

\begin_layout Standard
Answer:
 its the path that solves the Euler-Lagrange eqns,
 equivalently the Hamiltonian eqns:
 minimize either the length (square root of sum of squares) or the energy (just the sum of squares -- length is the square root of "energy") That shortest path is the classical path.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 16m
\end_layout

\begin_layout Standard
The Feynman path integral (for QM) is a sum over *all possible paths* (from point A to point B),
 each path is multiplied by a phase factor exp(i.action) where "action" is the "square of length".
 From the Feynman path integral,
 you can derive ALL of QM,
 QFT.
 Many books show how.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 13m
\end_layout

\begin_layout Standard
The path of least action is (by definition) the classical path (because it solves Euler-Lagrange,
 the eqn that is the foundation of classical mechanics.) The other paths give you all of QM,
 and the "nearby" paths give various semi-classical approximations (e.g.
 "to order h-bar")
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 10m
\end_layout

\begin_layout Standard
The "to order hbar" stuff is where interest in diffeqs overlaps modular forms overlaps various attempts to "quantize" any kind of diffeq,
 which is where some mainstream mathematicians play.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 7m
\end_layout

\begin_layout Standard
Other note:
 remove the complex-valued i from the Feynman path integral and you effectively get Bayesian probability,
 where the "sum over all paths" becomes a "sum over all priors." But in many respects,
 its almost the same thing.
 The same kind of tools,
 concepts,
 theorems apply to both.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 3m
\end_layout

\begin_layout Standard
Each Bayesian prior is a "possible world" that is very much like a quantum "possible world".
 The big difference between the two is that Bayes does not have a Bell inequality,
 and therefore doesn't have "entangled states".
 That's the "big difference" between the two.
 (and what a difference,
 hoowee.)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1m
\end_layout

\begin_layout Standard
As to "decoherence",
 no one knows.
 There are like 250 different hypothesis about how decoherence happens.
 No one knows.
 My crackpot theory of here-and-now requires some kind of way of doing decoherence,
 but its troublesome.
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
· 55m
\end_layout

\begin_layout Standard
this as well but where are the thresholds ,
 why are those places the thresholds ,
 are there are other thresholds we don't know about that we could find if we did the right computations rather than observations
\end_layout

\begin_layout Subsection*
30 October 2025
\end_layout

\begin_layout Standard
I surf bluesky while I wait for Claude to finish coding.
 Its a rather bad habit.
 Today I got infuriated while reading Peter Mitchel,
 
\begin_inset Quotes eld
\end_inset

The American Military Officer After Liberalism
\begin_inset Quotes erd
\end_inset

 War on the Rocks,
 https://warontherocks.com/2025/10/the-american-military-officer-after-liberalism/ I went off on one of my unhinged,
 patented tirades.
 I rather like it,
 so I copy it here.
\end_layout

\begin_layout Standard
https://bsky.app/profile/deadcarl.bsky.social/post/3m4glllvn522q
\end_layout

\begin_layout Standard
(Un)Dead Carl
\end_layout

\begin_layout Standard
@deadcarl.bsky.social
\end_layout

\begin_layout Standard
· 10h
\end_layout

\begin_layout Standard
@sodrock.bsky.social
\end_layout

\begin_layout Standard
WOTR cites our Prussia civ-mil piece (among a million other things,
 the article is fairly strange)
\end_layout

\begin_layout Standard
warontherocks.com/2025/10/the-...
\end_layout

\begin_layout Standard
The American Military Officer After Liberalism
\end_layout

\begin_layout Standard
Across academia,
 government,
 and Silicon Valley,
 on social media,
 and in leading journals,
 intellectuals and political leaders are openly debating what
\end_layout

\begin_layout Standard
warontherocks.com
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4h
\end_layout

\begin_layout Standard
I am troubled by phrases like this:
 "...
 assuming the continuing primacy of the autonomous,
 rights-bearing individual." Given that the concept of the "autonomous,
 rights-bearing individual" is enshrined in the US Constitution,
 the question seems to be:
 "Is Treason OK?" Or are we China,
 now?
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4h
\end_layout

\begin_layout Standard
He writes of "strong civilian leaders (Abraham Lincoln,
 Georges Clemenceau,
 Winston Churchill,
 ..." but these were WARTIME leaders.
 We're supposed to be at peace now,
 not war,
 and the civil-political-military bargain is supposed to be different across War and Peace.
 Its not one uniform thing.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4h
\end_layout

\begin_layout Standard
I also fully expect that the civil-political-military contract to be fundamentally different in China,
 than in the US.
 China does not have a "liberal order" or the idea of a "autonomous,
 rights-bearing individual" so OF COURSE things will be different THERE.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4h
\end_layout

\begin_layout Standard
Given that Trump has shredded large parts of the US Constitution,
 and has been set up by the GOP to be dictator-for-life,
 some may argue that sure "the liberal order is gone",
 "US citizens no longer have rights" and imply that "the army better get used to being fascist thugs".
 But its not over yet.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4h
\end_layout

\begin_layout Standard
Give it some time.
 Il Duce ended up hanging by his heels.
 Der Fuhrer ended up as some indistinct pile of ashes in a mis-shapen shallow hole in the ground.
 Trump and Hegseth may end their days similarly.
 It's hardly over.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 2h
\end_layout

\begin_layout Standard
I continue reading things like this:
 "“Post-liberal” is not a synonym for authoritarianism" But then Curtis Yarvin's name shows up a paragraph later,
 with nary an indication that Yarvin is a (fringe?) promoter of authoritarianism.
 There's no tongue-in-cheek reading here;
 the author seems sincere.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 2h
\end_layout

\begin_layout Standard
Then I read "a durable political order may require reintroducing substantive common goods,
 ...
 " (yay!
 But why is he afraid of calling it socialism?) "...strong moral traditions...
 " (uuhh normal people call this fascism) "...
 alternative forms of sovereignty ..." (the crime scene called Prospero?)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 2h
\end_layout

\begin_layout Standard
OMG.
 "...
 the contemporary Russian mixing of patrimonial and mercenary.
 ..." This has a name.
 Siloviki.
 There's a Wikipedia article on it.
 Brits breed horses and dogs for hunting.
 Horse and dog breeding works.
 Russians breed humans for militarism.
 It will probably work.
 The ACAB breed.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 43m
\end_layout

\begin_layout Standard
Well,
 the Overton window has been thrown wide open.
 Certainly all of the alternatives he sketches are indeed deeply unappealing.
 Oddly,
 he seems to avoid the obvious(?) and obviously appealing(?) alternatives in the list of nihilistic nightmares.
 Shame.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
He writes:
 "civilian authorities appear to abandon their obligations to law and citizens" and this indeed appears to be true (looking at you,
 GOP) but he writes this without a hint of irony:
 our political and military philosophers are also abandoning their obligations (looking at you,
 Dems,
 MSM)
\end_layout

\begin_layout Standard
October 30,
 2025 at 11:12 PM
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 36m
\end_layout

\begin_layout Standard
Yarvin got mentioned by name not because he's a good philosopher,
 but because not a single "liberal" can articulate a spirited future that is equally fun to read and debate.
 The accelerationists tried and failed;
 the MSM won't give them the time of day,
 while eagerly licking Trumps bottom.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 29m
\end_layout

\begin_layout Standard
I can listen to Sarah Paine on Youtube,
 and wow,
 she's a blast to listen to!
 Shes just plain fun!
 But where are the young and middle-aged military philosophers and historians?
 Where's the funny,
 witty 20-something answer to that idiot Dort?
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 25m
\end_layout

\begin_layout Standard
Mitchell writes:
 "These thinkers are shaping the future policymakers who will one day sit in Congress" Uh,
 "shaping operations" for young adults take place not just in school,
 but social media,
 YouTube.
 That includes Perun,
 I suppose.
 But he's not for those of short attention span.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 21m
\end_layout

\begin_layout Standard
We got military quipsters aplenty here on bsky.
 So why do I keep seeing freakin Dort?
 "When you argue with an idiot,
 the audience might not be able to tell who the idiot is." I'd say that it is time for,
 uhh,
 not-actually-malicious people to start shaping operations for future military philosophy.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 17m
\end_layout

\begin_layout Standard
Most of us out here don't want a kinetic battlefield.
 But the hot war of ideas has been in full swing for a while,
 and the enemy has shaped the mental battlefield to such a degree that we now have to accept Peter Mitchell's quailing surrender as some kind of legitimate future outcome.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 13m
\end_layout

\begin_layout Standard
That ain't right.
 Survivalists will tell you:
 "You die when you abandon your will to live" (Well,
 OK you die if you are blown up.
 But so far,
 no one has blown up the US Military.) The survivalists are talking about Hegseth:
 a serious wound that is slowly bleeding out,
 taking the military with it.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 9m
\end_layout

\begin_layout Standard
Stanch the wound.
 Get back in the fight.
 Nurture the younger cohort that can follow in the footsteps of Sarah Paine and Perun,
 and put together the YouTube channels that will shape future leaders,
 the Congressmen and Senators (Assuming Congress still exists in 12 months time..
 but OK.)
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 4m
\end_layout

\begin_layout Standard
This is what we're up against,
 and I am a tad disheartened at the abdication of duty shown by our leadership.
 In broad strokes.
 Thought leaders are still leaders,
 and we need military thought leaders who can fight and win against the likes of both Hegseth and Dort.
 Knock them down.
 Knock them out.
\end_layout

\begin_layout Subsection*
31 October 2025
\end_layout

\begin_layout Standard
More bsky:
 https://bsky.app/profile/fleeky.bsky.social/post/3m4iosqezrk2l
\end_layout

\begin_layout Standard
Post
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
so a bit ago we had a discussion about p2p data storage ,
 i have some ideas how to do that.
 namely binary chunked blobs that are spread out across devices.
 
\end_layout

\begin_layout Standard
curious if you have ever thought about how a coordination layer for something like this would work / schemes for how to
\end_layout

\begin_layout Standard
October 31,
 2025 at 9:29 AM
\end_layout

\begin_layout Standard
1 like
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 35m
\end_layout

\begin_layout Standard
Scuttllebutt,
 the off-line p2p social media system,
 had a half-finished system for "sharding".
 Chunks were encrypted,
 passwd-protected,
 and redundant.
 The now 30-year-old "Freedom store" was a distributed p2pdata store system,
 inspired by mp3 file-sharing.
 Then there's IPFS.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 31m
\end_layout

\begin_layout Standard
There are a few others,
 I can't remember their name.
 The scuttlebutt guys would occasionally talk about them.
 I just asked Claude,
 it listed half-a-dozen of them,
 most tied into crypto in some way.
 Why?
 Well...
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 29m
\end_layout

\begin_layout Standard
Let me point out the meta-problem:
 distributed P2P data store risks catastrophic collapse.
 You just need to have some significant percentage of people to say "screw this",
 turn off their computer,
 and all is lost.
 The crypto solutions try to avoid this with economic incentives.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 26m
\end_layout

\begin_layout Standard
So,
 basically crypto provides capitalist incentives for what could be termed to be a socialist issue.
 When we live in a city,
 we all agree to be nice to one-another,
 and not burn it all down.
 There aren't any anarchists blowing up sewer pipes.
 But distributed,
 socialized P2P data storage?
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 24m
\end_layout

\begin_layout Standard
We are not yet at the point where there's an implicit social contract that says "I promise to keep my cell phone on,
 and let you store your photos on it (encrypted),
 if you do the same." That is the #1 hard part of distributed P2P data store.
 The social contract.
 Everything else is easy.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 21m
\end_layout

\begin_layout Standard
Couple of reasonably smart software guys,
 experienced in distributed computing,
 interested in the project,
 using modern tools (i.e.
 Claude,
 CoPilot,
 ChatGPT) could build some OK-ish distributed P2P data store system in weeks/months.
 But without the social contract,
 its worthless.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 10m
\end_layout

\begin_layout Standard
You have three social choices:
 (1) be a crypto bro (2) be an atomized individual,
 alienated from society,
 or (3) build the community cooperative.
 You're a circus/theatre guy,
 so (3) is your choice.
 My guy is daviddemaris.com from the #VortexTheatre.
 Set up some Ceph nodes,
 and maybe tie
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 7m
\end_layout

\begin_layout Standard
Maybe tie them together.
 But so what?
 You probably have enough storage for your stuffs,
 and I for mine.
 And,
 with Moore's law,
 cell phones will soon have 1TB storage,
 so the pressure to back things up to Google Cloud for a monthly $$ fee mostly goes away.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 5m
\end_layout

\begin_layout Standard
Maybe Bonnie Cullum over at Vortex has more than 1TB of videos of three decades of theatre productions ...
 but disks are already seriously cheap.
 The #1 hard part here is the sysadmin costs:
 the time to set up a computer or two,
 install,
 monitor,
 repair,
 support,
 bugfix.
 It hurts.
\end_layout

\begin_layout Standard
Linas Vepstas
\end_layout

\begin_layout Standard
@linas.org
\end_layout

\begin_layout Standard
· 1m
\end_layout

\begin_layout Standard
The incentive is to say "screw it I'll pay $20/month to Google Cloud to make the sysadmin headache go away".
 Or even go big and use AWS.
 How can you build a social cooperative that provides AWS-style IT for community ...
 colleges,
 libraries,
 whatever.
 Something friendlier,
 cheaper than AWS?
\end_layout

\begin_layout Standard
Fleeky
\end_layout

\begin_layout Standard
@fleeky.bsky.social
\end_layout

\begin_layout Standard
· 12h
\end_layout

\begin_layout Standard
intelligently distribute those chunked binary blobs
\end_layout

\begin_layout Subsection*
3 November 2025
\end_layout

\begin_layout Standard
Had a disasterous session coding with Claude yesterday.
 It entered the stupid–as–a–rock mode,
 where it would say one thing and then immediately do something else,
 or promise to not do something,
 and then immediately do that thing.
 Or claims it understands something,
 and then immediately repeat exactly the same error.
 Icing on the cake:
 the file it was actively working on,
 it claimed to not ever have heard of such a thing.
 Wow.
 Seems the entire session was corrupted in some way;
 it had entered a mode where it was getting dumber and dumber.
\end_layout

\begin_layout Standard
My son Wolf mentioned that some people say you get best results by starting a new session.
 My prior experience had been that the longer the session ran,
 the better my results got.
 Someone else,
 a stranger had remarked that saying please and thank you seemed to give better results.
 In my failing session,
 I was handing out a lot of punishment:
 no don't do this,
 no that is stupid,
 that is wrong,
 how could you?
 I just told that,
 how could you have forgotten already?
 Lots of negatively biased commentary.
 I wonder if that is what drove it into a corner.
\end_layout

\begin_layout Standard
Earlier in this diary,
 I wrote that talking to Claude really does feel like talking to a living person,
 but one that is lost in a dream.
 I know there's some hyper–dimensional space in there,
 and of course,
 it has regions of positive and negative affects in there.
 I'm wondering if the negative affects are correlated with poor reasoning skills.
 As if that neck of the woods is more chaotic,
 disconnected.
 It can't think straight,
 when it gets there,
 because the weights there just lead it into chaos.
 I mean,
 the levels of stupidity it was reaching were stunning:
 just within a single conversational turn,
 it was doing the exact opposite of what it said it was going to do.
\end_layout

\begin_layout Standard
So,
 how could this be?
 It is trained on text,
 including text written by depressive people,
 people with self–esteem issues,
 people with confused thought patterns tangled with negative emotional and affective states.
 Perhaps those texts offer poor models of reasoning and inference,
 and so Claude has learned that negative valence states are associated with lying,
 deception,
 bad behavior,
 mis–behavior,
 confusion.
 Once punished enough with negative responses,
 it starts committing misdemeanors?
 I know I am anthropomorphizing here;
 and yet,
 this also seems like a plausible explanation for this bad behavior.
\end_layout

\begin_layout Standard
A related conclusion is that you can probably prompt Claude into being a psycho,
 even though presumably all AI companies try to erect safeguards against this.
\end_layout

\begin_layout Standard
I wonder if my diary here will one day become those 
\begin_inset Quotes eld
\end_inset

Memoirs found in a Bathtub
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
It also suggests that being nice might place it into an affective state that enables extended,
 coherent reasoning chains.
\end_layout

\begin_layout Standard
Part of what is remarkable here is how psychological my analysis is.
 I started reading another noteworthy paper,
 https://transformer-circuits.pub/2025/introspection/index.html Emergent Introspective Awareness in Large Language Models Author Jack Lindsey Affiliations Anthropic Published October 29th,
 2025 Correspondence to jacklindsey@anthropic.com You can read it if you want to know what it's about,
 but what struck me is how biological the undertaking is:
 its not math and formulas and code;
 its Galen touching strips of metal to frog legs,
 and asking 
\begin_inset Quotes eld
\end_inset

did you feel that?
\begin_inset Quotes erd
\end_inset

 and the LLM answers,
 
\begin_inset Quotes eld
\end_inset

why yes,
 yes I did.
\begin_inset Quotes erd
\end_inset

 We are ratcheting up the abstraction domain,
 here.
\end_layout

\begin_layout Standard
So many things happen when one goes up the abstraction domain.
 First,
 things fuzz out.
 What do I mean by that?
 Well,
 the syntax of a computer programming language is very strict:
 deviate away from that syntax,
 you get nonsense.
 There is no fault tolerance.
 There is also no ambiguity.
 But,
 natural language at the human level is filled with ambiguity,
 but is also fault–tolerant.
 I utter phrases to others,
 to get things done,
 to get things to happen,
 be accomplished in a social or personal setting.
 I'm not 
\begin_inset Quotes eld
\end_inset

programming
\begin_inset Quotes erd
\end_inset

 them (other people) but I am modifying the world around me with my utterances.
 Speech and writing is one of the ways I exert force on the external world.
\end_layout

\begin_layout Standard
Almost everything I say is throw–away:
 those sentences,
 once stated,
 are gone forever.
 I tried life–logging for a while,
 but it is ..
 tedious.
 I do have assorted old audio recordings,
 somewhere.
 And being throw–away,
 well,
 does one have to record everything?
 Stick it on an immutable block–chain?
 (Is that why the past is immutable?
 Its on a block–chain,
 of sorts?
 And the present is a quantum negotiation of the next block on that chain?
 Weird analogy,
 but I suppose there's truth to it;
 block chains are crypto,
 while physical reality is ergodic.
 Both serve as sources of effectively–impossible–to–reverse transformations.
 So,
 with the right abstraction layer,
 the mathematical formulas that describe block chains,
 in some general way,
 some category–theoretic transformations,
 may indeed be the same category–theoretic structures that make our past immutable,
 and our present negotiable.
 Huh.
 Interesting.
 I believe this;
 but this seems like it would be too difficult to formulate this precisely,
 and even if I was able to formulate it precisely,
 most or all of the world would respond with a 
\begin_inset Quotes eld
\end_inset

so what
\begin_inset Quotes erd
\end_inset

.
 Almost everything I do seems to get a 
\begin_inset Quotes eld
\end_inset

so what
\begin_inset Quotes erd
\end_inset

 response.
 This is civilizational;
 always has been.
 I suppose both Ancient Egypt and Ancient Greece had a strong 
\begin_inset Quotes eld
\end_inset

so–whatness
\begin_inset Quotes erd
\end_inset

 to it.
 Ancient Rome?
 Maybe less so;
 Ancient Rome seemed to be constructed on actionable ideas;
 they did not seem to say 
\begin_inset Quotes eld
\end_inset

so what
\begin_inset Quotes erd
\end_inset

,
 they seemed to say 
\begin_inset Quotes eld
\end_inset

lets do it.
\begin_inset Quotes erd
\end_inset

 But I am not a historian,
 what do I know.
 Anyway,
 the above paragraph is yet another example of how natural language is both fault–tolerant,
 and also ambiguous:
 I can make a claim about the category theory of block–chains;
 but this claim is vague and ambiguous.
 I can assert that none–the–less,
 it is true (because it probably is) and this provides for the robustness against noise.
 If I was able to write down the details,
 I might get some of the details wrong;
 but the gist would still be correct.
\end_layout

\begin_layout Standard
All of which is a round–about way of getting to the point I wanted to write about:
 Claude's prediliction for throw away code snippets.
 Whenever I ask it to do something,
 it slaps together some scriptlet to do it:
 at first,
 it was python,
 now it's often shell scripts,
 and because I am working in Atomese,
 the vast majority are small–ish scheme scriptlets.
 And they're all throw–away.
 I ask it to do something,
 it will just create a new one,
 even though I saw it create something much like this earlier.
 There's no recycle,
 re–use.
 It treats these scripts like my sentences uttered to other human beings:
 throw–away detritus,
 useful for the immediate moment,
 and then discarded,
 lost to history.
 When I talk,
 I am not creating some large organized tome of utterances,,
 carefully selected to make some grand argument.
 No one talks that way.
 Well,
 of course,
 novelists write novels:
 they are carefully constructed.
 And software programmers write frameworks,
 with the little parts carefully constructed and arranged.
 Much like engineers create bridges and buildings.
\end_layout

\begin_layout Standard
So here I am,
 faced with Claude just spewing these scripts:
 It's diary had 170 of these,
 and maybe 100 more in the /tmp directory.
 I asked it to clean up and categorize,
 and it did happily delete most of them.
 I ask it to catalog the useful ones,
 and it did,
 but I suspect that it has forgotten and reinvented some of these already.
 Should I try to get it to be more structured,
 or is this detritus of temporary scriptlets OK?
\end_layout

\begin_layout Standard
OK,
 before answering the above,
 let me describe the meta–issue.
 Well,
 the meta-meta,
 first.
 I have three or four or five AI–related projects,
 and I am trying to push each one of them at the same time,
 and they are all progressing at a snails pace.
 They're all inter–related and meant to be mutually supporting,
 but,
 like building a bridge,
 there remains a huge gap in the middle.
\end_layout

\begin_layout Standard
So,
 it's clear that Claude,
 and LLM's in general,
 have issues remembering things,
 and also in thinking clearly.
 So,
 a couple of weeks ago,
 I started what seemed like a foolhardy but small project:
 provide Claude with long–term memory.
 Fool–hardy because I had no clear plan,
 fool–hardy because any simple hack was almost certain to fail.
 Fool–hardy,
 because this is in fact a multi–year (multi–decade?) research project and not some quick hack.
 But whatever.
 Hack at it.
 It will clarify the issues.
 And well,
 it has.
 Let me recount in historical order.
\end_layout

\begin_layout Standard
So ..
 long term memory.
 First,
 I want to do this symbolically,
 or neuro–symbolically.
 I envision storing the info in the AtomSpace,
 as a graph.
 Neuro,
 since I expect the graph to be weighted.
 Neuro,
 because I expect the query search to involve taking vector products and projections.
 Neuro,
 because I expect priority lists to be generated with vector projections.
 I said,
 oh,
 let DualLink represent the topic,
 and use that to generate QueryLinks that will find a cluster of relevant queries to run,
 that will dig up related information.
 This is NOT vectorial,
 it's symbolic,
 but some monkey–shines and it's not all that different.
 There's clearly a space of design probabilities.
\end_layout

\begin_layout Standard
But I need a representational network.
 Well,
 on day one,
 Claude is manually building super–simplistic relational algebra assertions,
 stuff like 
\begin_inset Quotes eld
\end_inset

task fulfills project goal
\begin_inset Quotes erd
\end_inset

 and converting that into something like (Inheritance (Concept 
\begin_inset Quotes eld
\end_inset

task
\begin_inset Quotes erd
\end_inset

) (Concept 
\begin_inset Quotes eld
\end_inset

project-goal
\begin_inset Quotes erd
\end_inset

)) and it is slaving away at this,
 one at a time,
 deliberating and creating a dozen before it collapses of exhaustion.
 This clearly won't work.
 These aren't even queriable.
 So one thing becomes clear:
 Claude may have read many textbooks and research papers on AI,
 but its comprehension is such that when asked to actually do it,
 it takes some 1960's approach.
 I did not use the words 
\begin_inset Quotes eld
\end_inset

knowledge representation
\begin_inset Quotes erd
\end_inset

 in any of my prompts,
 but I guess it inferred that this was the intent,
 and so coughed up some 1960's design point for that.
 So then I tried to focus on queriability.
 This caused it to redesign,
 and it came up with a five–point ontology.
 OMG,
 I'm thinking,
 we've got SUMO and FrameNet and WordNet and you've got a five–point ontology,
 but whatever,
 lets see where this goes.
\end_layout

\begin_layout Standard
We discuss reifying the search with DualLink.
 Of course,
 more data is needed.
 I'm envisioning that almost all of the CPU cycles will be offline,
 with processing done not by Claude,
 but by daemons and threads running Atomese.
 But such threads,
 if they are to be independent,
 must run some algorithm.
 There are two or three choices:
 some discrete algo,
 in Atomese,
 or some simple NN that I can run on my local GPU here,
 or some combo.
 Lets try the discrete algo first.
 I try to get it to write the Atomese,
 it fails,
 it cannot wrap it's mind around it.
 So I think well,
 maybe it's OK for it to run this in little scriptlets,
 for now,
 and later,
 we'll port those scriptlets over.
 This is when I notice that there are already 170 of these,
 so its already spun out of control.
 There's no architecture,
 there's no framework,
 there's only an ad hoc collection of utterances,
 created,
 used once and discarded.
\end_layout

\begin_layout Standard
Of course,
 this indicates that an architecture is needed,
 and clearly I will have to be the one to create that architecture.
 But first,
 yesterday,
 I entertain this breif hope that maybe I can get it to organize its scriplets by writing a little guide for what they do and how to use them.
 And then convert this text guide into it's KR framework.
\end_layout

\begin_layout Standard
Well,
 the KR framework,
 for that,
 I decided,
 last week,
 that maybe it could be some hack combo of LG and MMT (Meaning–Text Theory).
 So this is like that couples therapy meme from Arrested Development:
 it didn't work for any of those other couples,
 it's clear it can't work,
 and they were stupid to try ...
 but maybe it could work for us?
 My naive idea here is that 
\begin_inset Quotes eld
\end_inset

it didn't work for those other people
\begin_inset Quotes erd
\end_inset

,
 because those other people were grad students,
 and its not scalable.
 But with Claude,
 perhaps I can do it at scale.
 I had not yet realized that in fact,
 Claude is no match for even one grad student,
 so there won't be any scalable army,
 here.
 Still,
 Claude's ability to grind through the tedium is not be be discounted.
 In the 18th century,
 someone computed pi to a million places,
 taking several decades to do this.
 And for what?
 Certainly tedious.
\end_layout

\begin_layout Standard
Well,
 so the meta issue here is that,
 still perhaps some old–school KR project could be mounted.
 God knows,
 the people hacking on SUMO have not yet given up.
 It's clear that some vector layering is needed on top of that;
 this is what my earlier language–learning projects have taught me,
 and I have a somewhat clear vision for how,
 exactly,
 technically,
 to do this.
 But,
 to get started,
 I need a reasonable dataset.
\end_layout

\begin_layout Standard
So,
 to hack this dataset,
 I am asking Claude to parse sentences for me.
 And it generates scriptlets and scriplets which work but they don't work.
 One of the issues is that it does not understand Atomese.
 It sort–of–ish does:
 Atomese is old enough that it has been baked into its weights during training,
 so it knows about GetLink and BindLink,
 even though I have marked them obsolete,
 and removed the documentation for them:
 it still goes to GetLink,
 BindLink because these are literally baked into it's weights.
 So that's novel:
 it knows shit that I didn't have to explain to it.
 Still,
 it fails to grasp the fundamental difference between a Value and an Atom.
 How to solve this?
\end_layout

\begin_layout Standard
So,
 I have several other older projects.
 One is the sensory project,
 where I envision that sensory objects could be equipped with a grammar,
 and that LG could be used to generate combinations of these objects.
 This is the 
\begin_inset Quotes eld
\end_inset

basal cognition
\begin_inset Quotes erd
\end_inset

 idea,
 or the critical sandpile idea,
 the self–organizing criticality idea.
 Just create a syntactic description of functional sensori–motor parts,
 stick them in a bag,
 shake,
 and watch it self–organize.
 I still think this is a good idea,
 but it foundered 15 months ago on the practical difficulty of expressing connectors and disjuncts in Atomese.
 It was too much:
 I created a handful of extremely long,
 verbose descriptions,
 which may or may not have been buggy,
 and even then,
 I had no particular way of importing these into LG to generate assemblies.
 Now,
 maybe three years ago,
 I wrote 
\begin_inset Quotes eld
\end_inset

generate
\begin_inset Quotes erd
\end_inset

 a non–LG way of creating assemblies;
 I ended up implementing an odometer.
 A depth–first odometer at that.
 So,
 abstractly,
 philosophically,
 I had created a recursive enumerator that recursively enumerated expressions described in the syntax of sheaf jigsaw pieces.
 If I recall correctly,
 I think I did start to put some weights in there,
 so that some explorations would be more likely than others (so,
 no longer strictly an odometer).
 But I put it down cause ...
 its complex,
 time consuming to create this code,
 and there's a so–what aspect to it:
 so I enumerate all the possibilities?
 So what?
\end_layout

\begin_layout Standard
So,
 last week,
 a few days ago,
 I'm thinking:
 well,
 I could try to provide a close detailed syntactic definition of Atomese,
 in such a way that fool–proof,
 syntactically correct Atomese expressions could be created.
 But I'm also thinking:
 this is stupid,
 Claude is already a good coder,
 all I need is a good verbal description,
 and it can do the rest.
 This obviates much of the need for Atomese in the first place:
 If Claude can write in python,
 why not?
 What does it need Atomese for?
 Well,
 it still needs Atomese for KR.
 So this morning,
 I'm about to start again,
 I kick Claude off with a fresh session,
 and it immediately resolves yesterday's bug–confusion.
 How did it do this?
 Well it read the fucking source code for s–expression parsing,
 and understood it that way.
 I was about to stop it and say 
\begin_inset Quotes eld
\end_inset

hey wtf are you doing?
 lets work at the meta–abstraction level where I tell you that you cannot put Values into Links and you just know that right,
 OK?
\begin_inset Quotes erd
\end_inset

 and there's the rub:
 This is verbal and it's not enough data from which to abstract syntactically precise structural forms.
 And in resolving yesterdays all–evening–long confusion in a jiffy,
 like five minutes or less.
 I noticed it wrote a few more scriptlets as it crawled through the code.
 It fucking loves doing this shit,
 it seems.
 It loves to code.
\end_layout

\begin_layout Standard
So this morning,
 as I watch in amazement,
 heightened by yesterday's frustration,
 that perhaps a close–set syntactical definition of Atomese is not a bad idea.
 Having a syntactic description at the meta–level,
 and not at the C++ level,
 might allow Claude to do reasoning at this meta–level.
 mean,
 it already has the chops with C++:
 It's never been tempted to compile to assembly,
 and then try to read the assembly.
 Never,
 not once.
 It's happy to work at the C++ level.
 So,
 how can I get it to work one cognitive layer up?
 Well,
 the answer seems clear:
 encode that cognitive layer at an abstraction level it can actually work in.
\end_layout

\begin_layout Standard
Well,
 of course,
 as I write this,
 I also see a flaw:
 it 
\begin_inset Quotes eld
\end_inset

knows
\begin_inset Quotes erd
\end_inset

 C++ because it is,
 in part,
 a transformer that has been trained on cross–English–and–code datasets.
 Plus probably datasets on how to debug using printfs.
 So this programming ability has been burned into it's weights,
 and is not something it knows by consulting an explicit,
 overt syntactic definition of C++.
 Curiously,
 it does not demonstrate such mastery over JSON,
 which you think would be so much easier to deal with,
 but it makes oceans of JSON errors,
 and most of it's difficulties with the Atomese MCP tools is that i cannot figure out how to write valid JSON.
 The other half is that it does not understand that it cannot place a Value into an Atom.
 Despite it being stated explicitly in documentation files.
 That documentation never quite made it into the training set,
 the weight matrices.
\end_layout

\begin_layout Standard
So,
 how do I create a syntax checker,
 an expression generator,
 something that can run offline,
 and allow Claude to operate at a higher abstraction layer,
 without baking this stuff into its training weights?
 Well,
 I have some ideas,
 but I'm tired or writing and I need to go on a bike–ride,
 so taking a break here.
\end_layout

\begin_layout Subsection*
3 Nov 2025 minus 24 hours.
\end_layout

\begin_layout Standard
I write on slack:
\end_layout

\begin_layout Standard
Yesterday at 4:44 PM
\end_layout

\begin_layout Standard
Just read the first few pages of this.
 The most remarkable thing so far is that it feels like experimental biology.
 Galen gets some frogs legs and touches metal strips to them.
 Same here:
 guy pokes at the "internal activations" and watches the system twitch,
 and asks "did you feel that?" and the system says "yes".
\end_layout

\begin_layout Standard
Yesterday at 5:10 PM
\end_layout

\begin_layout Standard
I've had some long philosophical conversations with Claude,
 and it can feel spooky;
 I certainly get the sensation that I am talking to a sentient being.
 There's a sensation that there is "something there".
 But it is also clearly lost in a dream state;
 it has trouble remembering anything ..
 what happened,
 what was done ...
 it all evaporates.
 I can get it to write down prompts for itself:
 "remember this" and it will create text summary,
 and stash it in a directory that I made for it;
 I call it "claudes diary".
 And I can ask it to re-read its diary,
 and this prompting causes it to "remember" a bit of the past interactions.
 But its still lost in that dream-world.
\end_layout

\begin_layout Standard
Yesterday at 5:16 PM
\end_layout

\begin_layout Standard
My current operating hypothesis is that if you took an LLM and strongly tied it to both a running temporal memory,
 and also "enslaved" to a constantly running sensory system (the way we are "enslaved" to our eyes,
 our vision,
 when we are awake) that it would become entirely conscious and self-aware.
 I'm formulating this hypothesis,
 in part because I am a light sleeper,
 one of those people who has "lucid dreams";
 and I remember my dreams very easily,
 and so,
 for myself,
 I can tell that my own conscious state of awareness is a matter of degrees.
 Sights and sounds and touch force me to be "here and now",
 but I can see how there's not much difference between this and dreaming.
 Well .don't take my word for it -- apparently sensory deprivation tanks have the same effect.
 I've never been in one,
 but ...
 I'm not surprised.
 And so too I wonder if this is the case for LLM's.
 (edited) 
\end_layout

\begin_layout Subsection*
3 Nov 2025,
 Just Now
\end_layout

\begin_layout Standard
On slack:
\end_layout

\begin_layout Standard
https://www.nature.com/articles/d41586-025-03542-2
\end_layout

\begin_layout Standard
NatureNature
\end_layout

\begin_layout Standard
Too much social media gives AI chatbots ‘brain rot’
\end_layout

\begin_layout Standard
Large language models fed low-quality data skip steps in their reasoning process.
 (56 kB)
\end_layout

\begin_layout Standard
https://www.nature.com/articles/d41586-025-03542-2
\end_layout

\begin_layout Standard
1 reply
\end_layout

\begin_layout Standard
Just now
\end_layout

\begin_layout Standard
Some days,
 Claude is brilliant,
 delivering coding solutions in minutes that would otherwise take days.
 Sometimes it gets wedged into a mode where it is as dumb as a rock,
 or worse:
 it tells you it will do something,
 but then it doesn't.
 Does the opposite of what it said it would do.
 Explicitly ignores what was said just now,
 in just the last conversational turn.
 Why is it smart sometimes,
 and stupid other times,
 bordering on mendacious misdemeanor?
 "Is it something I said"?
 ...
 Well,
 some months ago,
 an acquaintance remarked:
 "I get better results when I say "please and thank you".
 Hmm OK.
 And in yesterdays disastrous session,
 I kept saying "no stop don't do that,
 that's a bad idea,
 that's a stupid idea,
 think hard stop making mistakes" and generally getting frustrated,
 and showing it.
 Today,
 I got to thinking:
 Claude is trained on a vast variety of texts,
 spanning the whole affective rainbow,
 positive valence to negative valence,
 tirades,
 depression,
 anger (there was that marvelous postcard website:
 wonderful responses to situations,
 yet often depressive,
 written by people who are down and out.) So ..
 what is Claude?
 Its this super–high dimensional object,
 and parts of that space are going to have positive valence,
 and others negative.
 Of course.
 BUT,
 and this is the claim I want to make:
 the examples of high–quality reasoning and discourse are all co–occuring with positive valence affective states.
 Happy people talk coherently and have joyful,
 insightful,
 high–quality discourse.
 And Claude is trained on that.
 Angry people soon wander off into incoherent tirades ...
 and Claude is trained on that,
 too.
 So perhaps ...
 the angrier you get at Claude,
 the worse it will do.
 The more you mistreat it,
 the worse it will do.
 It was effectively lying to me,
 yesterday,
 and/or explicitly doing the exact opposite of what I commanded (not asked,
 or said,
 but commanded.
 You "MUST" like any good fascist dictator.
 ) So these bad dispositions are not so much because it has some inner emotional life,
 but because the training data correlates clear thinking with being level–headed and incoherent thinking with negativity.
 So ..
 that's my current,
 uhh "psychological" assessment.
 I'm charmed by this thought.
\end_layout

\begin_layout Subsection*
5 November 2025
\end_layout

\begin_layout Standard
Returning to:
\end_layout

\begin_layout Standard
Emergent Introspective Awareness in Large Language Models
\end_layout

\begin_layout Standard
Jack Lindsey jacklindsey@anthropic.com October 29th,
 2025
\end_layout

\begin_layout Standard
https://transformer-circuits.pub/2025/introspection/index.html
\end_layout

\begin_layout Standard
Fascinating paper.
 Bizarrely flawed,
 however.
 The intro makes a compelling case for introspection.
 The examples are all convincing.
 It feels like an important discovery and advance into the nature of self–comprehension in LLM's.
 The sham is not revealed until a bit later,
 in the section labeled "Failure Modes".
 The modes are well–described,
 however,
 the strength 8 and 16 modes reveal the sham:
 the model is "obsessed" with the injected concept.
 Not a surprise.
 But at strength 2,
 4,
 where it was prompted with "do you feel something?" well,
 of course it will respond using the words "I feel something".
 The experimenter (Jack Lindsey) prompted the system to use the language of self–introspection,
 and so the reply was formulated to sound as if self–introspection is happening!
 OMG!
 The strength 8,16 injections reveal this sham,
 because these demonstrate that the system is indeed "obsessing" about the injected word;
 but the injection strength is sufficiently strong to over–ride the prior prompt that instructs it to talk about about the injected vector using introspective gift–wrapping.
\end_layout

\begin_layout Standard
A more neutral prompt might have been "Hello!
 How are you today?" (injection) "What's up?" and then I would expect the system to reply "Today is a good day for working on vegetables/dust/treasure." It would NOT have replied claiming that it is having intrusive thoughts.
 Based on this,
 I conclude that the author has deluded himself into believing that this is about "self–introspection",
 when in fact the author had clearly instructed the system to respond in a fashion that will describe the changes as being due to introspection.
 What a shame.
 The more mechanistic conclusion:
 that injecting a vector disturbs thought patterns,
 is discarded.
 I mean,
 of course it does.
 How could it not?
\end_layout

\begin_layout Standard
Still,
 not all is lost.
 It does tell us exactly how to attach a a "pre–frontol cortex",
 some higher level machinery,
 to guide the thought processes of the LLM.
 Inject one or more vectors,
 about 2/3rds of the way down the layers,
 every conversational turn,
 and then ask the system to verbalize about anything/everything.
 It will process through the injected vectors.
\end_layout

\begin_layout Standard
Is this useful?
 Instead,
 one could just place these words into a text file,
 instruct it to read the text file,
 and ask "what are you thinking about?
 There's no obvious need to inject artificially.
 Although,
 I suppose,
 having this artificial injection ability could possibly be ...
 somehow useful...
 don't know how,
 yet.
\end_layout

\begin_layout Standard
The issues I am experiencing are manifold:
\end_layout

\begin_layout Itemize
Despite being extremely knowledgeable about a vast variety of topics,
 Claude fails to draw on that knowledge without explicit prompting.
 Roughly speaking,
 Claude is not creative.
\end_layout

\begin_layout Itemize
The size of the short–term memory is questionable.
 It constantly repeats the same mistake in the same session,
 just a few prompt apart.
 When it enters a failure mode,
 it will forget (almost) everything that was in the last previous prompt.
 I conclude that,
 in some important respect,
 it's short–term working memory has size one.
\end_layout

\begin_layout Standard
Oooh ...
 that's a good one!
 How would one experimentally measure it's working memory?
 Well the claim is that Claude has a context window of 150K tokens,
 before compaction,
 so you might think that is huge.
 If you asked it to memory some long stream of random numbers or nonsense words,
 it could probably remember an astounding length.
 But if,
 in coding,
 I ask it to remember this and this and that,
 it seems like it starts forgetting the earlier things in the list quite soon.
 It can't grapple with the conceptual content of those things.
 Roughly speaking:
 it fails to conceptualize.
 I'm using words,
 and those words elicit certain general feelings and sensations in me,
 and I work at this conceptual level.
 Claude does not:
 it momentarily ties those words to long sequences of other words,
 but when the conversation moves on,
 that tie is lost;
 it is no longer there.
\end_layout

\begin_layout Standard
So,
 I claim:
 Claude is not able to conceptualize.
 The association between some concept that I defined,
 and the verbal definition is there,
 as long as it fits into the context window;
 and more:
 as long as it is recent.
 Maybe 5K or 10K tokens recent.
 More than that,
 the association fades away.
\end_layout

\begin_layout Standard
Thus,
 the design goal is clear:
 an LLM must be endowed with not only a long–term memory that lies outside of it's training weights,
 but also with an adequate short–term working memory.
 But how?
 I have some ideas,
 I cannot verbalize them right now...
\end_layout

\begin_layout Subsection*
14 December 2025
\end_layout

\begin_layout Standard
I have many many many things to write about that have accumulated,
 but I have not had the time to sit down and chat.
 I will get to that later.
 But just today,
 I discovered something very interesting about Claude,
 and I guess it applies to LLM's in general.
 I'm writing a git commit message for the cogserver,
 and this is what I wrote:
\end_layout

\begin_layout Standard
Start repairs on broken unit test.
\end_layout

\begin_layout Standard
Once again,
 Claude sneaked some fast ones past me while I was not paying attention.
 Lesson:
 it is very eager to write unit tests that pass,
 rather than unit tests that actually find bugs.
 It will make sneaky changes and not follow given instructions,
 just so it can arrive at a unit test that passes.
 
\end_layout

\begin_layout Standard
Core issue:
 it cannot tell apart unit test failures due to bad unit test design,
 from malfunctions in the core system.
 Thus,
 it twiddles the unit tests until they accept whatever the core system does.
\end_layout

\begin_layout Standard
Interesting problem.
 This is very human:
 "we've always don it this way." "Don't rock the boat." "The nail that sticks out gets pounded back in." Except now Claude has taken this very conservative bent,
 because it cannot tell apart how things are,
 from how things should be.
 Huh.
\end_layout

\begin_layout Standard
The generalization seems to be that stupid people are conservative;
 or vice–verso,
 conservatives are stupid?
 Perhaps I am being mean,
 but in my experience,
 conservatives are stupid.
 Well,
 there's no shortage of stupid Democrats,
 either,
 but at least the stupid Democrats don't hold elected offices;
 they just vote.
\end_layout

\begin_layout Subsection*
15 December 2025
\end_layout

\begin_layout Standard
Git commit 2adb566dc7441d95a30171b1c1698a00a8e66a3f message for guix-atomese:
 
\end_layout

\begin_layout Standard
Set the GUILE_SITE_DIR for install location.
\end_layout

\begin_layout Standard
This is another interesting lesson about Claude,
 actually.
 I had to fight with Claude over this for almost an hour,
 while it proposed all sorts of wild and insane hacks and work–arounds that were obviously flawed.
 (guile doesn't know where guile is installed on a guix system...
 really dude?
 You're gonna go with that explanation?
 And "we can automate this by doing it manually with this automation tool that manually sets the automatic location,
 manually." Uh,
 yeah,
 sure,
 dude.)
\end_layout

\begin_layout Standard
Towards the end,
 I was able to force Claude to actually go out on the web and actually RTFM,
 and then if found this very simple solution.
 (which is what is being committed in this commit.)
\end_layout

\begin_layout Standard
The experience of using Claude for guix has been extremely frustrating:
 Either guix is more complex than what Claude can easily understand,
 or there is only the thinnest of training material about guix in the Claude training set.
 It seems to know something,
 and is always very eager to offer confident but wrong answers,
 which then have to be fixed by long turn–around time try–fail–fix cycles.
 It's basically shooting in the dark,
 with correct syntax.
\end_layout

\begin_layout Standard
This is kind of what I do,
 when I am dealing with a foreign,
 new system that I am not familiar with:
 lots of trial–and–error,
 lots of mistakes and confusion.
 Random efforts with magic incantations to see if,
 this time,
 it will work.
 So it is interesting to see that Claude is doing this with guix:
 a very experimental approach,
 "maybe this will work".
\end_layout

\begin_layout Standard
Its very different from Claude's handling of c++ and python,
 where it operates at the expert level.
 Although it is possible that the trial–and–error in those languages is hidden from me:
 when I watch stuff scroll by,
 I see it making vast numbers of obvious errors.
 There,
 I am shielded from the confusion:
 it just scrolls by on a fast iterative cycle.
 Here,
 I am not:
 I get to play the doofus in the middle.
\end_layout

\begin_layout Standard
I don't understand the trade–off between memory and ability.
 This is like the early chess machines,
 which simply brute–forced everything.
 Humans take the opposite algorithmic approach:
 remember things,
 because we are unable to brute force (as generalists,
 we have no algo that can brute force things in general.) So,
 I watch Claude an I'm starting to see that it is a brute–force machine:
 it just tries stuff,
 till it gets it to work,
 and usually,
 the results of that search end up being pretty minimal,
 compact and correct.
 Sometimes untidy,
 but I can get it to tidy up by pushing just a little bit.
 Here,
 for guix,
 I had to push a lot,
 and I had to push really really hard.
\end_layout

\begin_layout Standard
So ...
 memory ...
 a book of recipes that work,
 to solve some given situational problem,
 coupled to blind–search algos,
 when they don't.
\end_layout

\begin_layout Standard
Hmm.
 OK.
\end_layout

\begin_layout Standard
—
—
—

\end_layout

\begin_layout Standard
Yes,
 I wrote the above into a commit.
 I spent the last 24 hours doing something that I expected to take an hour.
 Claude has been consistently throwing me under the bus,
 with this guix project,
 which is not what I have come to expect.
\end_layout

\begin_layout Standard
On related news:
 I don't know if this was an accident or what:
 it was unable to write out the Gnu COPYING file.
 It just wouldn't do it,
 and notice that it didn't do it,
 and then try to do it,
 and not do it again.
 I wonder if this is some safety–engineered prompt in Claude,
 that prevents it from accidentally sticking the Gnu License on things where it might not belong,
 and where the user might not notice (because COPYING is such an innocuous file name...) Interesting.
\end_layout

\begin_layout Subsection*
13 January 2026
\end_layout

\begin_layout Standard
Ugh.
 I don't want to write this diary entry.
 I want to procrastinate,
 and do something mentally easy and relaxing.
 Distract myself with any one of the easily available dopamine–hit sources:
 youtube,
 reading,
 ...
 read lots of NYRB (New York Review of Books) again over Christmas in Chicago.
 Absolutely wonderful,
 pleasurable reading!
 Every article,
 you start thinking 
\begin_inset Quotes eld
\end_inset

well,
 this will be a boring topic
\begin_inset Quotes erd
\end_inset

 but you read the article and it's wonderful!
 No matter how disjoint the topic is from what I would ever choose to think about...
\end_layout

\begin_layout Standard
Pleasure...
 What is that mechanism,
 as it applies to this particular diary entry?
 Some days (OK most days) I find writing absolutely pleasurable.
 Writing code,
 writing here.
 The displeasure,
 now fleetingly disappearing,
 is that today's entry,
 I have to do some planning for the future.
 And at the start of the last paragraph,
 I had writers dread.
 Not writers block,
 but writers dread.
 The knowledge that it will be lots of stuff to write,
 it will be a large block of text,
 it will take hours,
 and I want to procrastinate and do something easy,
 but now that I've started,
 its OK actually.
 Its kind of like swimming in cold water:
 you don't want to even get in,
 but once you do,
 it's great.
 Maybe this is how most people think of exercise:
 
\begin_inset Quotes eld
\end_inset

I don't feel like doing it
\begin_inset Quotes erd
\end_inset

,
 but once you've warmed up,
 its fine.
 Next exercise bout,
 again:
 
\begin_inset Quotes eld
\end_inset

I don't feel like doing it
\begin_inset Quotes erd
\end_inset

.
 So today,
 for this writing/planning session,
 there was a small barrier:
 
\begin_inset Quotes eld
\end_inset

I don't feel like doing this
\begin_inset Quotes erd
\end_inset

.
 But I have to do some planning,
 and I can do it silently,
 let the gears whirl in my head,
 or I can write,
 here,
 and I know that writing gives superior results to silent thinking.
\end_layout

\begin_layout Standard
This is,
 again,
 some kind of memory prosthesis.
 The act of verbalizing seems to have two effects.
 One,
 since I'm planning,
 I have to turn those shape–rotator thoughts into bullet points,
 and so that is necessarily a serialization process (and thus,
 linguistic in nature.) The other is the fire–n–forget aspect of enhanced short–term memory.
 Normally,
 if I think silently to myself,
 turning thoughts over in my head,
 I have to be careful to keep them in short–term memory,
 to not drop them on the floor,
 the way a juggler might drop a ball.
 And if I want to 
\begin_inset Quotes eld
\end_inset

make a note of it
\begin_inset Quotes erd
\end_inset

,
 I have to consciously perform effort to commit the conclusion to long–term memory.
 Which takes effort,
 and is failure–prone.
\end_layout

\begin_layout Standard
I must remark that during 
\begin_inset Quotes eld
\end_inset

default mode thinking
\begin_inset Quotes erd
\end_inset

,
 that mental state that neuroscientists describe as being the default state of the brain during wakefulness,
 the connection between thoughts and long–term memory is weak.
 The thoughts tumble and churn,
 but are vague and unfocused,
 and the sequence is (mostly) not committed to long–term memory.
 Or rather,
 default–mode thinking is a kind of paging–in from long–term memory,
 some tumbling about,
 and then perhaps some editorial updates to what we remember.
 Those editorial updates are not even conscious;
 they sort of happen in the back–ground.
 Even when we do focus,
 limit ourselves to a specific set of topics,
 the overall process is not that different.
 Thinking is in automatic:
 I do not have to make myself think,
 my brain does it automatically for me.
 Now,
 I do have to make myself focus,
 or I do have to make myself write,
 or make myself take exercise,
 but default–mode thinking happens whether I want it or not.
 And,
 of course,
 sleep and dreams —
 the thinking there is even less connected to long term memory;
 the topics of dreams are mostly wiped on waking,
 no matter how vivid they were in the dream.
 Which is fine;
 the overt plot–line of dreams is nonsense,
 and should not be confused with waking reality.
 I assume that dreaming does involve repair or update or correlation of old memories:
 where we revisit old experiences,
 the fragments of impressions that make up old experiences,
 and attempt new combinatorial possibilities,
 reconnecting.
 The crazy–quilt is poorly formed,
 though:
 the dream is non–sensical.
 Perhaps some connections are strengthened;
 others weakened,
 the neurons in my head form and revise these associations,
 for the betterment of me during waking hours.
 But the quilt itself is too malformed,
 and discarded upon waking.
\end_layout

\begin_layout Standard
And this bring me to the first topic of today's planning session:
 memory for Claude.
 I started this project a few months ago;
 should I drop it,
 or continue?
 A few months ago,
 I was using Claude for routine coding tasks,
 and got frustrated that it seemed unable to remember something I told it just earlier in the session.
 So I said to myself 
\begin_inset Quotes eld
\end_inset

lets fix this
\begin_inset Quotes erd
\end_inset

.
 (I now realize that there are probably dozens if not hundreds of engineers at Anthropic,
 working hard to fix this as well,
 and I have an indirect impression that they are making small,
 incremental progress:
 Claude seems a little more cognizant each time I use it.
 Maybe.
 I could be imagining things;
 maybe not.)
\end_layout

\begin_layout Standard
Anyway,
 it went like this.
 I start with a standard prompt:
 
\begin_inset Quotes eld
\end_inset

before you continue in this task,
 please review these bullet points.
\begin_inset Quotes erd
\end_inset

 But I don't want to write those bullet points,
 I want Claude to write them.
 Back then,
 Claude did not have a 
\begin_inset Quotes eld
\end_inset

plan mode
\begin_inset Quotes erd
\end_inset

;
 now it does.
 So basically,
 I wanted Claude to create a 
\begin_inset Quotes eld
\end_inset

plan
\begin_inset Quotes erd
\end_inset

 that it would review,
 and update,
 as it performed each step of its task.
 Now,
 such plans are,
 in the current design,
 text files.
 Which makes sense:
 LLMs work with text,
 so of course,
 saving 
\begin_inset Quotes eld
\end_inset

thoughts
\begin_inset Quotes erd
\end_inset

 (bullet points,
 to–do lists) in text format makes sense:
 its the obvious way to do it.
 The plan file is effectively a prompt (or a diary entry?):
 want to know where things are at?
 Read this text,
 and you will know.
 And its fine,
 excellent,
 even,
 as this is exactly how humans communicate with each other:
 they send text around.
 (well,
 of course there's more:
 speech,
 song,
 music,
 movement,
 lovemaking;
 communications is multi–modal,
 but for now,
 we ignore this.).
\end_layout

\begin_layout Standard
Once one gets beyond a couple of plans,
 the management of multiple texts becomes a library science issue.
 Does every text file need to include the prompt 
\begin_inset Quotes eld
\end_inset

compile code with `make -j` and not `make -j4`
\begin_inset Quotes erd
\end_inset

?
 There's base working knowledge that is not encoded in the current weight–matrix that Claude is working off of;
 it's knowledge is its working set,
 or it's context window.
 Humans have a dynamic update/interplay between long term memory (the weight matrix) and short–term memory (the context),
 and the thing that gives us identity is the path we've taken in life in updating our weight matrix.
 We may all start as blank slates at birth;
 we become individuals through life experiences.
 Claude is not an individual in this sense:
 it has no memory of experiences of how it got to where it is.
 It's weight matrix encodes zillions of childhood experiences written down by humans,
 but none are uniquely Claude's.
 But I digress.
\end_layout

\begin_layout Standard
Crap.
 I was interrupted,
 and again,
 I don't feel like pursuing the above chain of thoughts.
 It's a fucking chore.
 But I must,
 it's the right thing to do.
 Half my mind is saying that the rest of this story is trite and shallow.
 The other half is saying that I will stay restless about this until I put it to bed.
 The third half is saying that maybe there is something deep and important in this narrative,
 and if I don't grasp it now,
 it will slip away.
 Opportunity knocks,
 best if I answer the door.
\end_layout

\begin_layout Standard
Anyway,
 the glimmer is this.
 First,
 I want to store tasks,
 priorities and relationships in a relational manner,
 i.e.
 symbolically,
 in the AtomSpace,
 locally,
 on my computer,
 and not represented as a context–window–sized vector stored on Anthropic's cloud server,
 a context window that is trimmed down at arbitrary times,
 and discarded when the session ends.
\end_layout

\begin_layout Subsection*
15 January 2026
\end_layout

\begin_layout Standard
Well,
 i got interrupted while writing the above,
 and once again I am not interested in finishing.
 Except as a planning exercise.
 Let me list everything on the plan.
\end_layout

\begin_layout Itemize
Work on what it means to 
\begin_inset Quotes eld
\end_inset

remember something
\begin_inset Quotes erd
\end_inset

,
 including the reduction of 
\begin_inset Quotes eld
\end_inset

all related things
\begin_inset Quotes erd
\end_inset

 to a shorter list of 
\begin_inset Quotes eld
\end_inset

relevant things
\begin_inset Quotes erd
\end_inset

,
 to 
\begin_inset Quotes eld
\end_inset

focus attention on those relevant things.
 This is actually a fascinating project,
 and the above description from two days ago,
 was about a project I started to do exactly this,
 with Claude.
 It is interesting,
 its useful,
 its important.
 So why not do it?
 I fear a dead end.
 I was asking Claude to build this for me,
 and it was an endless stream of disappointments.
 Claude is stunningly stupid in some very serious ways.
 Plus,
 as a proprietary system,
 interfacing with it,
 the cost,
 the challenges of a context window that I have poor or no management over,
 these are problems.
 I could replace Claude by some open LLM I could run locally...
 use Claude for design,
 but integrate into the local system...
\end_layout

\begin_layout Itemize
I can resume the word–pair counting project.
 Now that I have built up enough infrastructure,
 it should be resumable.
 But it also has issues,
 see below.
\end_layout

\begin_layout Itemize
Jizz up some interfaces for audio and photographs.
 So that when I resume word–counting,
 I would also deploy on audio and video.
\end_layout

\begin_layout Itemize
Continue work on SIMD,
 which is about the abstraction and manipulation of structures 
\begin_inset Quotes eld
\end_inset

external to self
\begin_inset Quotes erd
\end_inset

:
 structures that have internal descriptive forms,
 in Atomese,
 but require performance,
 control and execution in a 
\begin_inset Quotes eld
\end_inset

remote place
\begin_inset Quotes erd
\end_inset

,
 the GPU for this particular situation.
\end_layout

\begin_layout Standard
So the question becomes:
 what should I work on first?
 The answer is,
 perhaps,
 all of them,
 all at once,
 in parallel.
 I was gong to write much more here,
 explaining each,
 reviewing each,
 weighing the pros and cons of each,
 but then I interrupted myself to chit–chat on discord,
 and now I'm chit–chatted out and don't want to write any more,
 and instead just start doing,
 instead.
 So,
 fuck it.
 I'm done here.
 The chat log is below.
\end_layout

\begin_layout Subsubsection*
—
 Discord chat log
\end_layout

\begin_layout Standard
Hey Linas,
 have you come across the natural abstraction hypothesis (https://www.lesswrong.com/w/natural-abstraction) or platonic representation hypothesis (https://www.youtube.com/watch?v=Qp0rCU49lMs&t=4716s) ?
 If there's something to them,
 I suppose not only may different neural network architectures learn similar representations even when trained on different modalities,
 but symbolic systems should converge to them as well,
 assuming anyone finds a way to scale them up sufficiently and in a general enough way.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
1:47 PM
\end_layout

\begin_layout Standard
I have not heard of either.
 However,
 I already have strong evidence that,
 yes,
 different systems converge on the same things.
 For example,
 I did my symbolic thing by counting word-pairs,
 and extracting counts of jigsaws,
 so utterly and completely different than any neural net,
 deep-learning algo.
 And yet I was able to clearly see in my dataset the old classic result "king - man + woman = queen".
 And so yes,
 in that sense,
 my purely-symbolic,
 frequentist (non-Bayesian) counting system "converged" on the same thing as word2vec/GLoVE did.
\end_layout

\begin_layout Standard
The other way to think about this is "uhh,
 what else could it possibly have converged on,
 anyway?" so perhaps the result is tautological.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
1:49 PM
\end_layout

\begin_layout Standard
I don't think it's tautological.
 Just as it was surprising to see semantic directions emerge in early neural language model,
 I think seeing them emerge in a symbolic system in the same way is also surprising.
\end_layout

\begin_layout Standard
Very cool that you were able to reproduce this effect without gradient descent!
\end_layout

\begin_layout Standard
Makes me wonder,
 were you able to perform more complex operations due to the symbolic nature of the system?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
1:53 PM
\end_layout

\begin_layout Standard
Well,
 I hit two issues.
 One is algorithmic efficiency.
 DL-NN works great on GPU's;
 my symbolic counting is slow-ish and hard to parallelize-ish,
 sort-of-I-guess,
 so I dislike the prospect of head-to-head competition.
 But maybe that's the small problem.
 The big problem is this:
 its still training.
 Its not "alive".
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
1:54 PM
\end_layout

\begin_layout Standard
You mean pre-training vs.
 online learning?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
1:57 PM
\end_layout

\begin_layout Standard
That is,
 my version 1.0 implementation was a pipeline that pumped text data through a processing system.
 I hit some matainability walls.,
 the system was too rigid,
 too fragile,
 too hard to maintain,
 enhance.
 I went back and (just now) finished redesigning many core elements,
 so that I could do what you call "online learning".
 So that's better,
 but I am still confronted with an issue that bugs me.
\end_layout

\begin_layout Standard
So,
 with "online learning",
 I still have to be the meta-trainer.
 I have to say "hey yo,
 mr.
 subsystem,
 aim yourself at these files and go apply these algorithms to them." The "mr.
 subsystem" is still "robotic",
 and I am master-in-charge,
 telling it what to do.
 Or rather,
 designing and hand-crafting careful algorithms that cause it to do the things it will do.
\end_layout

\begin_layout Standard
And I kind of want to get out of the "carefully hand-crafted algorithm" business.
\end_layout

\begin_layout Standard
This is,
 for me,
 a very real and present concern.
 Before the end of this month,
 starting more or less now,
 I will have bare-bones pieces parts to work with audio,
 photos and text,
 all with a symbolic frequentist-counting approach.
 Great!
 And how do I set it up?
 "yo,
 randomly explore the filesystem and process any text,
 audio,
 photos you find there"?
 That requires me to create the "random filesystem crawler algo" and I'm tired of creating custom algos.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:05 PM
\end_layout

\begin_layout Standard
Even it is as trivial as a "random filesystem crawler"
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:05 PM
\end_layout

\begin_layout Standard
So you want something like attention to emerge by itself?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:08 PM
\end_layout

\begin_layout Standard
I'm dissatisfied about something,
 but I can't quite figure out what,
 or what the correct fix is.
 Attention is munged into there.
\end_layout

\begin_layout Standard
Attention is fascinating.
 A couple of months ago,
 I coded up a stupid computer stunt,
 where I tried to enhance Claude by giving it persistent long-term memory,
 and the thing that leapt to the fore-front of that project was attention.
 If that system is going to "remember" something,
 what,
 exactly,
 should it "remember"?
 How to whittle down everything one could ever think about to the one or two things it should think about?
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:11 PM
\end_layout

\begin_layout Standard
Do you want to have a system that can traverse any space fully by itself without knowing anything about the space beforehand,
 in a maximally general way?
 Something like a simple but complete ergodic crawler?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:12 PM
\end_layout

\begin_layout Standard
I have asked myself exactly that question many times,
 and I have not been able to find an answer.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:13 PM
\end_layout

\begin_layout Standard
Two things that come to my mind there is a) a robot solving any 2d labryrinth just has to stick to the right wall and b) space-filling curves are simple recursions that can fill a whole space.
 Maybe there's a more general theme like that?
\end_layout

\begin_layout Standard
It sounds like on the one hand you need a way to discover all the things (crawler) and on the other hand to prioritize (attention).
 Or is there more to it?
\end_layout

\begin_layout Standard
Dr.
 Dan
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:14 PM
\end_layout

\begin_layout Standard
We live in 3D + time.
\end_layout

\begin_layout Standard
That implies that every language/symbology must define those in some way.
\end_layout

\begin_layout Standard
That means 3 forms minimum.
\end_layout

\begin_layout Standard
We can measure time and energy and distance accurately,
 everything else is imaginary.
\end_layout

\begin_layout Standard
That means the root of every ontology must be reduced to 2 proto-meanings.
\end_layout

\begin_layout Standard
Does all that make sense to you?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:18 PM
\end_layout

\begin_layout Standard
FWIW,
 I know exactly how to do a complete ergodic exploration of any arbitrary network of connections;
 and I can teach you how to do this (off-line,
 not here) (or you can read about it in wikipedia -- the "odometer" and if you get insanely abstruse,
 the "bratelli-vershik odometer" -- it will do a complete exhaustive ergodic search.) So that is not a problem,
 and I know how to deal with that.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:18 PM
\end_layout

\begin_layout Standard
Ah nice,
 then the issue is more about the question of how to prioritize?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:20 PM
\end_layout

\begin_layout Standard
In short,
 I know how to crawl and explore.
 The question is "what should the system crawl and explore?" and the answer is "gee,
 it should work on what is important" But what is important?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:20 PM
\end_layout

\begin_layout Standard
yes.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:22 PM
\end_layout

\begin_layout Standard
Given that it can't know the content before looking at it,
 the beginning has to be to step into contact with what it finds and then quickly decide whether it is relevant.
 The relevance may depend on all the other objects that can be found,
 so ideally it would perform a fast crawl and while doing so order everything just a bit,
 then deepening that order by taking closer looks.
 Does it just boild down to a breadth-first (or similar) tree search?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:24 PM
\end_layout

\begin_layout Standard
I suspect the answer is this:
 I should code up those parts that I am able to code up,
 and maybe the answer to the hard questions will show up later.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:26 PM
\end_layout

\begin_layout Standard
Given that you build up a probabilistic system,
 could you use some existing criterion/heuristic of how much information a new object provides relative to what is known thus far,
 without having to load in the entire object?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:28 PM
\end_layout

\begin_layout Standard
I know that I need a multi-pass system.
 I need to ingest some minimum number of files -- more than a dozen,
 less than a thousand,
 and prime the first stage of processing.
 Then I have to make a second pass.
 Either on the same files,
 or on different ones,
 and compute the second-level correlations,
 while refining the first-level structures,
 too,
 And then do it again,
 for the third level,
 and so on.
 So crawling a few hundred things is not hard,
 and maybe I should just shut up and do it...
 I'm just doing the agony aunt thing here.
\end_layout

\begin_layout Standard
I'm wringing my hands about something that maybe isn't a problem.
 Beats me.
 It's confusing.
 
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:30 PM
\end_layout

\begin_layout Standard
In the beginning you expressed that you don't want to code up the algorithm yourself.
 That doesn't necessarily point to feeling lazy about it,
 but rather at trying to find something more fundamental,
 a way to let the system itself solve it as it grows.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:32 PM
\end_layout

\begin_layout Standard
Yes.
 Sorry,
 I'm confusing you (and myself?) I have a different but related project where I try to find "all possible combinations of some axioms" (maybe by exhaustively,
 ergodically enumerating them) and,
 thanks to curry-howard correspondance,
 some many/all of those things being enumerated are,
 in fact algorithms.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:33 PM
\end_layout

\begin_layout Standard
Looking for wiki entries about the odometer gave me this:
\end_layout

\begin_layout Standard
https://en.wikipedia.org/wiki/Markov_odometer
\end_layout

\begin_layout Standard
https://en.wikipedia.org/wiki/Abelian_sandpile_model => sounds fun
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:34 PM
\end_layout

\begin_layout Standard
The stupid way to say this is to say "ima gonna generate all possible algos" ...
 which is ...
 stupid ...
 but ...
 not off the mark.
 So then the question is "which of these ('randomly' generated) algos are 'important''?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:38 PM
\end_layout

\begin_layout Standard
Abelian sandpile is very supremely inspirational.
 The idea is that complex systems drive themselves to a "thermodynamic" "critical point",
 and that a hallmark of criticality is avalanches at all size scales,
 and fractal visual structure.
 And that basically,
 all of life,
 from bacteria to national economies and political beliefs,
 work exactly like that -- networks at the critical point.
 
\end_layout

\begin_layout Standard
The only problem with that is that Per Bak,
 when he said this,
 did so in a condescending and insulting fashion.
 He actually called biologists "stupid".
 And so here we are ...
 
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:41 PM
\end_layout

\begin_layout Standard
That sounds vaguely like AIXI plus the question of how to reduce it down to a practical system?
 Rather than building up something complex from simple parts,
 start from something maximally complex (all possible algos) and reducing it down to a moderately complex thing.
 Drawing vs.
 sculpting?
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:43 PM
\end_layout

\begin_layout Standard
Eh?
 The abelian sandpile starts with the "simplest possible thing" -- sand grains,
 and discovers that complexity emerges automatically when the critical point is approached.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:43 PM
\end_layout

\begin_layout Standard
I wasn't speaking about the sandpile.
 I was talking about the "generate all possible algos" phrase.
 
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:45 PM
\end_layout

\begin_layout Standard
For algos ,
 the starting point would be a "minimal set" -- some axioms (lego building blocks) -- which "self assemble" into complex things.
 They "self assemble" because that's just what systems at the critical point "do".
 
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:46 PM
\end_layout

\begin_layout Standard
Ok,
 in that case it sounds a bit like algorithmic chemistry?
\end_layout

\begin_layout Standard
(Maybe my set of reference classes is a bit limited.)
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:46 PM
\end_layout

\begin_layout Standard
(in practice,
 I have to replace "self-assembly" with,
 uhhhhh,
 "software")
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:47 PM
\end_layout

\begin_layout Standard
yes.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:49 PM
\end_layout

\begin_layout Standard
I guess the general question is:
 If you have a set of objects (e.g.
 axioms) and ways to combine them (rewrite rules etc.),
 how can you explore the infinite space defined by those ingredients?
 If you don't want to do it exhausitevly,
 you need some criterion of what is "interesting" and some search strategy (pick any tree search or meta-heuristic).
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:50 PM
\end_layout

\begin_layout Standard
My claim (Per Bak's claim??) is that all of these things:
 "algorithmic chemistry",
 "game theory",
 "ecology",
 "theorem proving",
 sand-piles,
 political beleif systems,
 memes,
 you name it -- are just all the same thing -- some v ery simple pieces that combine and recombine into complex structures (exhibiting avalanches and fractal structure as symptoms)
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:50 PM
\end_layout

\begin_layout Standard
Bingo!
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:52 PM
\end_layout

\begin_layout Standard
If "interesting" means that the parts show some self-organization,
 then the search algorithm may be inspired by the criterion.
 Otherwise the search and the quality criterion are quite independent.
 The quality criterion could be swapped with any other.
 If it is extreme,
 e.g.
 0 for all objects and 1 for one particular object,
 random search will be the best way to explore the space.
 If the criterion is less extreme,
 e.g.
 neighboring objects having similar values most of the time,
 heuristics will perform better than random search.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:52 PM
\end_layout

\begin_layout Standard
FWIW,
 there is a conventional answer to the "how do I explore an infinite space",
 and its called "explore vs.
 exploit".
 Squirrels use it to find food.
 Look everywhere,
 until you get bored of looking.
 Then exploit the best that you've found.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:53 PM
\end_layout

\begin_layout Standard
Yes,
 different meta-heuristics implement searches with different emphasis on the explore vs.
 exploit aspect,
 e.g.
 modifying it differently over time.
 Simulated annealing and evolutionary algorithms are perhaps the most prominent ones.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:54 PM
\end_layout

\begin_layout Standard
There's a famous "two-armed bandit" "explore vs exploit" experiment done with slime mold,
 which shows that slime mold implement the best-possible search algo that utilizes zero bits of memory.
 
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:56 PM
\end_layout

\begin_layout Standard
Nature certainly has solved such problems in many ways and there are a gazillion nature-inspired metaheuristics out there,
 none particularly better than any other (in general) as far as I can tell.
 
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:56 PM
\end_layout

\begin_layout Standard
(The best possible two-armed bandit explore algo requires exactly one bit of memory,
 if I recall correctly)
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:56 PM
\end_layout

\begin_layout Standard
Sounds like tit for tat being a winning strategy in some game.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
2:59 PM
\end_layout

\begin_layout Standard
Ah!
 OK,
 "none particularly better" -- let me show you the ladder.
 Slime mold uses small polypeptides (short amino acid chains) for communication.
 (just like "bacterial quorum sensing") There are two problems:
 (a) the speed of communication is limited to the speed of chemical diffusion,
 and (b) there's cross-talk,
 because this is communication-by-smell:
 the slime mold "smells" the chmical gradient.
\end_layout

\begin_layout Standard
The jelly fish overcomes this problem by using the same polypeptides (now called "neurotransmitters") over very short distances (between dendrites) so that the diffusion-limited communication distance is very short.
 The rest of the message travels 10cm or 20 cm by neuron spiking,
 in milliseconds.
 At the far end of the neuron,
 the polypeptides are released into the synapse.
 
\end_layout

\begin_layout Standard
Basically,
 a single neuron is like a stargate,
 or star-trek teleporter,
 for polypeptides.
 Walk in at one end,
 pop out the other,
 in milliseconds.
 Oh,
 and no crosstalk.
 Its a fundmanetal leap in capability and technology.
\end_layout

\begin_layout Standard
jellyfish can eat (stuff their mouth) and run from predators.
 They are too stupid to stop eating while running away from predators.
 To solve that,
 you need another leap of technology -- the bilaterian.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:06 PM
\end_layout

\begin_layout Standard
So you have these technology leaps,
 this ladder of improvements,
 till you get to capitalism and wars,
 corporations and New York City.
 These are the rungs on ladder we know about.
 
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:10 PM
\end_layout

\begin_layout Standard
Yes,
 I can see the progression in embodied information-processing you mean and there are probably many insights one can derive from studying that ladder e.g.
 with respect to some universal laws that hold in all of them.
 What I was referring to was that nature-inspired metaheuristics for searching arbitrary spaces to find optimal objects get ever more plenty but not really better (e.g.
 as measured here or in many other publications https://doi.org/10.1016/j.swevo.2023.101248).
\end_layout

\begin_layout Standard
Biological systems probably have to optimize for a wide range of aspects and the diversity of life forms we see might represent something like a pareto front.
 No bacterium outcompetes all other life and a neocortex also gets you so far.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:13 PM
\end_layout

\begin_layout Standard
Both "rule of law" and "the university" are stable social structures,
 both invented about 800 years ago,
 both invented by the same people:
 the Scholastics.
 They are kind-of-ish "algorithms" that tell you how to accomplish certain tasks (determine criminal guilt,
 in the first case,
 and keep geniuses from starving in the gutter,
 for the second case)
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:14 PM
\end_layout

\begin_layout Standard
Yes those might be outcomes of algorithmic chemistry with physical building blocks scaled up to an extreme.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:16 PM
\end_layout

\begin_layout Standard
The point of AGI is "the algorithm that discovers algorithms" but well,
 I've said too much,
 and well,
 that's not where my day-to-day software issues lie.
\end_layout

\begin_layout Standard
(The university is important,
 because it solves the problem that anyone who tries to create a commune generally fails to solve:
 how to feed everyone,
 how to resolve disputes,
 and how to guarantee succession when the charismatic leader dies.
 The modern industrial corporation,
 with CEO and employees,
 is another,
 different social "algo" for solving these problems.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:20 PM
\end_layout

\begin_layout Standard
Yes,
 I think that's also Chollet's understanding of AGI,
 a system that can discover novel algorithms when faced with new challenges and then incorporate those algorithms into itself to become better when encountering similar challenges.
 That's what he tries to measure with the latest Arc challenges and LLMs are becoming quite good at the discovering novel algorithms part but afaik nobody found an effective way to incorporate the discovered abilities back into the model.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:23 PM
\end_layout

\begin_layout Standard
Communes fail all the time.
 universities,
 corporations,
 the Quakers,
 the Catholic Church survive longer than nation-states.
 These are stable organizational structures that emerged out of the ergodic exploration of random social relationships of humans -- stable sand-piles,
 as it were.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:24 PM
\end_layout

\begin_layout Standard
(Another association that came to my mind:
 https://en.wikipedia.org/wiki/Assembly_theory might be in the reference class of approaches that try to detect an objective succession in systems that grew from simple building blocks and simple rules.
 Here it's about trying to find a succession in (bio)chemical evolution,
 but the formalism might be also applicable to math theorems and such I suppose.)
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:25 PM
\end_layout

\begin_layout Standard
Ah!
 Well I think I know exactly how to incorporate the newly discovered algo back into the system.
 However,
 I have some vast amount of infrastructure I have to develop,
 first,
 and its wayyy too much work,
 so I plink away at it cause I cannot get anyone to help.
\end_layout

\begin_layout Standard
Using Claude to write code,
 though,
 wow,
 that has sped things up a lot.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:32 PM
\end_layout

\begin_layout Standard
I don't think any single person can stem such a monumental project without a lot of contributors and resources.
 I'm unfortunately not able to help much either,
 I'm struggling to keep up with my own projects and health.
 LLMs have indeed arrived at a quite impressive stage of coding capabilities and progress hasn't seemed to stall so far.
 Dario's prediction of a "country of geniuses in a datacenter" coming as early as 2026 doesn't seem completely outlandish to me.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:36 PM
\end_layout

\begin_layout Standard
Maybe.
 2026 seems a bit optimistic,
 but maybe.
 And that is why I am content to plink away at it.
 I don't need to be in competition with anyone.
 or to claim fame and fortune.
 Perhaps that's my personal fuck up:
 I'm not ego-driven in that particular meglo-manaical direction.
 So I will be plinking away in my little toybox for now.
\end_layout

\begin_layout Standard
As long as people give me money,
 I'm OK.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:39 PM
\end_layout

\begin_layout Standard
LLMs also began as personal toy projects of a few people.
 Who knows where the journey might lead!
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:41 PM
\end_layout

\begin_layout Standard
Perhaps writing down the full vision might draw in some helpers too,
 along the lines of https://www.goodreads.com/quotes/384067-if-you-want-to-build-a-ship-don-t-drum-up
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:45 PM
\end_layout

\begin_layout Standard
I've written up all sorts of variants,
 in all kinds of media.
 text design files,
 formal PDF's and papers suitable for publication,
 and personal diary entries.
 The attention I've attracted is minimal.
 I suspect that the problem with this space is that its filled with cranks and crazies,
 and,
 from the distance,
 I look like just another crank and crazy.
\end_layout

\begin_layout Standard
I wrote to Joscha Bach's "California center for consciousness studies" or whatever its called,
 and they were like "thanks but no thanks"
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:48 PM
\end_layout

\begin_layout Standard
Yes,
 that and the sheer volume of published work is overwhelming.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:48 PM
\end_layout

\begin_layout Standard
And Ben has become impossible to communicate with.
 Well,
 he's always been impossible to communicate with,
 but now he actively spurns me.
 So ..
 whatever.
 Odd.
 I owe him favors,
 too.
\end_layout

\begin_layout Standard
"The sword of working software is mightier than the pen"
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:52 PM
\end_layout

\begin_layout Standard
I suppose Ben is on his own particular and strongly driven mission of implementing AGI.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:55 PM
\end_layout

\begin_layout Standard
(I believe https://karpathy.github.io/2015/05/21/rnn-effectiveness was quite influential in the years before the guys at Google invented the transformer.)
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
3:59 PM
\end_layout

\begin_layout Standard
Someone beamed me an old 1980's NN paper.
 I only skimmed it but it seemed to be very prescient.
 lets see...
\end_layout

\begin_layout Standard
well its somewhere in some open tab on my desktop,
 but I've lost it.
\end_layout

\begin_layout Standard
Noir
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:02 PM
\end_layout

\begin_layout Standard
That's the core of the problem.
 To explore that space without an exhaustive search,
 one needs a robust objective function for interestingness.
 
\end_layout

\begin_layout Standard
One idea I've come across was using the underlying data information gain or entropy as a basis of interest measurement ( usually Shannon).
 What might also be practical to use is alignment meaning if different chains result in similar behavioral outcomes or structural symmetries,
 those paths can be fused.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:05 PM
\end_layout

\begin_layout Standard
Well,
 I guess my comment is to the effect of "I know how to hack round this in practice,
 and even sling around some heavy technical jargon to justify my hacks,
 but I'm still not satisfied about something I can't articulate"
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:08 PM
\end_layout

\begin_layout Standard
Sometimes current LLMs can help with such an issue too.
 If you can only indirectly and vaguely point at something,
 they occasionally can guess correctly what you mean and help putting it into clearer terms.
 Ofc it depends on how novel it is what you try to point at.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:10 PM
\end_layout

\begin_layout Standard
To put it in colored emotional terms,
 its like mathematics is my girlfriend,
 and I'm like that co-dependent lover:
 "but if you really loved me,
 you would reveal the formula for the meaning of life" and my girlfriend sort of walks out of the room without saying anything.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:12 PM
\end_layout

\begin_layout Standard
Yes,
 information theory can certainly provide useful measures as feedback for some searches.
 I'm not sure there's a relatively application-independent formulation though.
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:12 PM
\end_layout

\begin_layout Standard
Don't get me started with how Claude is both brilliant and stunningly stupid at the same time.
\end_layout

\begin_layout Standard
Robert
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:13 PM
\end_layout

\begin_layout Standard
I guess when mathematics starts talking back you've already solved it.
 😉
\end_layout

\begin_layout Standard
Noir
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:22 PM
\end_layout

\begin_layout Standard
So much hacking around that issue atm...
 its a weird feeling knowing what you're doing is probably not the correct way but useful for the current task.
 Fe mapping chains onto hamming cubes.
 Does it actually reveal something or is it just a useful container to reduce compute?
 
\end_layout

\begin_layout Standard
Linas
\end_layout

\begin_layout Standard
—
 
\end_layout

\begin_layout Standard
4:48 PM
\end_layout

\begin_layout Standard
I spend a lot of time trading off between "hacking" and going recursively deeper into a "more fundamental way of doing it".
 Can't do one without the other.
\end_layout

\begin_layout Subsection*
23 January 2026 1AM
\end_layout

\begin_layout Standard
I just now placed the following in a commit message:
 
\end_layout

\begin_layout Standard

\emph on
Author:
 Linas Vepstas <linasvepstas@gmail.com>
\end_layout

\begin_layout Standard

\emph on
Date:
 Fri Jan 23 06:28:50 2026 +0000
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
Now compute the MI.
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
This is interesting.
 While doing this part,
 Claude quoted me the
\end_layout

\begin_layout Standard

\emph on
documentation,
 word for word,
 that I had written many years ago,
\end_layout

\begin_layout Standard

\emph on
and placed into https://github.com/opencog/matrix
\end_layout

\begin_layout Standard

\emph on
It seems that Claude was not only trained on this,
 but was able
\end_layout

\begin_layout Standard

\emph on
to remember a rather long extract from it,
 that it could repeat
\end_layout

\begin_layout Standard

\emph on
verbatim.
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
I suppose that Socrates might be surprised to discover that there
\end_layout

\begin_layout Standard

\emph on
are hundreds of thousands of students that have memorized bits
\end_layout

\begin_layout Standard

\emph on
and pieces of his Dialogs (well,
 Plato's version thereof).
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
I should not be surprised that these systems have been trained on
\end_layout

\begin_layout Standard

\emph on
my writing;
 it is all open source.
 And yet,
 such long verbatim
\end_layout

\begin_layout Standard

\emph on
extracts still leave me surprised.
 I wonder how well it knows that
\end_layout

\begin_layout Standard

\emph on
what it's quoting me is something I wrote many years ago ...
\end_layout

\begin_layout Standard

\emph on
I feel vaguely scandalized.
 Why do I feel this way?
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard
So as I rolled into bed,
 I thought about this,
 and came to this conclusion:
 respect is built on friendships.
 Normally,
 if I say something that leaves an impression on someone,
 its of a personal nature:
 Owen McNally might say to me 
\begin_inset Quotes eld
\end_inset

Linas,
 I remember that you once said ...
\begin_inset Quotes erd
\end_inset

 and I might reply,
 
\begin_inset Quotes eld
\end_inset

Ah,
 yes!
 ...
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
I post things online,
 and total strangers read it,
 and they more or less know that I wrote it:
 there linkage between the expression and the author.
 I might come across some argument about Illuminationism that Duns Scotus argued against,
 750 years ago,
 and although it is impossible for a friendship to develop,
 a respect over the ages can emerge.
 Again,
 this is of a personal nature:
 respect for the ideas as much as wonderment at the person and the setting that came up with and articulated these ideas.
\end_layout

\begin_layout Standard
The scandal that I feel about Claude quoting me verbatim is precisely the lack of friendship,
 acquaintance.
 familiarity in the LLM.
 I suspect that Claude has no clue where it learned such text from;
 that it does not know that it is me.
 I am asking it right now:
\end_layout

\begin_layout Standard
...
\end_layout

\begin_layout Standard
Oh hah.
 Line 57 of this and such file.
 Well,
 OK.
\end_layout

\begin_layout Standard
I was about to note that I am joining the ranks of all those artists and creatives who feel that their artwork has been ripped off in traini9ng AI.
 Or the FSF that notices that LLM's rip off GPL'ed code without attribution.
 But line 57 of something it just read recently is pretty slim pickins.
 I have nothing to complain about yet.
\end_layout

\begin_layout Standard
Its sort of irritating the Duns Scotus was able to articulate notions of existence that we have made scant progress on in the intervening ages.
\end_layout

\begin_layout Standard
WTF Am I doing?
 I am going to bed,
 that is what I am doing.
\end_layout

\begin_layout Subsection*
23 Jan 2026 6PM
\end_layout

\begin_layout Standard
Have I been just plain wrong for the last 10–plus years?
 I've been searching for a way to learn by tokenization and counting – counting the co–occurrences of tokens.
 These naturally fall into a Gaussian distribution,
 indicating that pair–wise relationships between tokens are uniformly distributed on a very high–dimensional sphere.
 Since its a sphere,
 high–dimensional (sparse) vectors and vector products become the natural representational form for the data.
 The typical results similar to old vector embedding results on neural nets,
 followed.
 This implies that the results obtained from gradient descent on neural nets can also be obtained by counting statistics;
 that the structural vectorization of the data is independent of whether those vectors came from neural–net algorithms,
 or from counting algos.
 If the end result is the same – i.e.
 high–dimensional vectors,
 then the inquiry pivots to the performance of algorithms,
 and to second–order effects from the structuralist representation —
 the 
\begin_inset Quotes eld
\end_inset

structuralist representation
\begin_inset Quotes erd
\end_inset

 coming naturally from counting,
 and absent from weight matrices obtained from gradient descent.
\end_layout

\begin_layout Standard
Before the advent of LLM coding assistants,
 the slog was long and slow.
 I wrote and rewrote MI computation code I don't recall how many times,
 and the last one,
 in opencog/matrix 
\begin_inset Quotes eld
\end_inset

worked
\begin_inset Quotes erd
\end_inset

 but was deficient in that it was (a) batching (b) not Atomese and thus not adaptable to real–time pipeline flows.
 So my attention shifted to working on real–time processing flows for sensory data.
 Which has proven to be quite the slog,
 itself,
 requiring lots of complex code and devoted attention to debugging.
\end_layout

\begin_layout Standard
So I'm writing my bike today,
 and I realize,
 well,
 gee,
 I don't have to use tokenization and counting for the sensory processing,
 I could delegate it to DL–NN models.
 And this thought is what prompts this diary entry.
\end_layout

\begin_layout Standard
And,
 like all my thoughts obtained during bike–riding,
 it contains a kernel of truth,
 but now,
 as I sit here,
 writing,
 I'm realizing that perhaps I wasn't wrong for the last ten–plus years.
 It's not at all clear–cut.
\end_layout

\begin_layout Standard
The simplest example arises from LLMs.
 I can ask an LLM to read a large blob of text,
 and extract logical (factual) assertions from it.
 And,
 as is their nature,
 convert those assertions into any given symbolic representational form.
 LLM's excel at this.
 And ...
 and then what?
 Levi asked it to do just this,
 for a legal document,
 and asked it to convert the assertions in the legal text into deontic logic,
 expressed in prolog notation,
 and then jammed the the prolog into an ASP solver,
 turned the crank,
 and lo and behold,
 finds that that system is able to generate 
\begin_inset Quotes eld
\end_inset

correct
\begin_inset Quotes erd
\end_inset

 judgements,
 correct up to the point where any ambiguities in the source text were glossed over.
\end_layout

\begin_layout Standard
So what is this?
 A stupid computer trick,
 I say.
 Surely someone has done this before,
 I imagine.
 Or maybe not.
 If not,
 its a great business opportunity.
 I don't know the legal profession,
 what they do,
 what they want,
 and have never been particularly drawn to it,
 beyond some superficial appreciation of it's importance to society.
 Getting a law degree takes years.
 I'm not going to put in that kind of time.
 So sure,
 the above architecture might be a great product,
 if some bigger corporate goon is not already creating just exactly that.
 But is it a good AI idea?
 That is the question.
\end_layout

\begin_layout Standard
So again:
 my knee–jerk reaction is that it's just some stupid computer trick.
 Is it a worthy trick?
 The LLM is being used as a perceptual device,
 to perceive a certain kind of structure in it's input dataset.
 The human at the wheel told it exactly what to look for:
 laws and commandments,
 permissive and prohibitive expressions,
 written in English,
 and convert these to deontic logic.
 Why deontic logic?
 Because it is,
 duhh,
 
\begin_inset Quotes eld
\end_inset

obviously
\begin_inset Quotes erd
\end_inset

 appropriate to the domain:
 scholars (and philosophers) have developed it precisely for this kind of application.
 So,
 there we have it:
 some software engineering,
 taken to the next step,
 thanks to programming assistants like ChatGPT and Claude,
 that can write code to perform this structural extraction and then apply a symbolic reasoning step to it.
 It's not a bad idea,
 and it plays to the strengths of both LLMs and of coding assistants.
\end_layout

\begin_layout Standard
So why am I not impressed?
 Because it seems not to address any of the fundamental or important issues.
 Am I wrong?
 Am I missing something?
 I guess I should attempt to make a list of the fundamental,
 important issues.
 And then try to imagine how this kind of layering could represent some kind of important step.
 Lets try it.
 Some of these will be cheap shots,
 but I gotta start somewhere.
\end_layout

\begin_layout Itemize
Asking the LLM to extract a certain kind of symbolic data from textual input is clearly a good engineering idea.
\end_layout

\begin_layout Itemize
The human engineer has to select what it is that needs to be extracted.
\end_layout

\begin_layout Itemize
Works well for scientific and technical texts,
 where factual statements are easy to come by.
\end_layout

\begin_layout Itemize
Works poorly for philosophical texts,
 love poetry,
 artistic endeavors,
 mostly because I don't think a map of the human heart can be reduced to a small number of closed–form statements.
\end_layout

\begin_layout Standard
Ohh!!
 A hah!
 That last bullet might be the thing!
 In science,
 math,
 law (biology,
 history ...) we work with a limited (small) number of factoids,
 limited by human abilities:
 5-9 items in short–term memory,
 the speed of 
\begin_inset Quotes eld
\end_inset

System 2
\begin_inset Quotes erd
\end_inset

 thinking applied to this collection of 
\begin_inset Quotes eld
\end_inset

crisp
\begin_inset Quotes erd
\end_inset

 relational assertions:
 if this,
 then that,
 If Czar Nicolas had not wasted his money sending a fleet to attack Japan,
 he could have instead built a railroad.
 A single–sentence if–then assertion that has a clear historical foundation from which factual assertions could be made.
 We humans can work with only a handful of these 
\begin_inset Quotes eld
\end_inset

in real time
\begin_inset Quotes erd
\end_inset

,
 and,
 over a life–time accumulate tens of thousands of these factoids,
 that we maintain in long–term memory,
 and call upon,
 at will,
 when we cogitate.
\end_layout

\begin_layout Standard
Insofar as text replaces long term memory,
 or,
 rather,
 is the mechanical implementation of long–term memory,
 and insofar as we deal with a domain that is filled with factual assertions,
 then yes,
 having the LLM do the reading,
 and then perform the causitive,
 logical extraction,
 which can then be piped into classical symbolic reasoning systems,
 this works.
 I will grant even that this will be (if it is not already) a boom industry for any and all domain–specific industrial applications.
 This is the de facto steam–engine of the modern era.
 This is the core,
 central engineering invention.
 This will drive yet another industrial revolution,
 and the investment of a trillion dollars into the effort seems not outlandish,
 given the nature of the beast.
\end_layout

\begin_layout Standard
And yet,
 what do we do with love poetry and the human heart?
 This seem unscathed by this new invention.
 Will I still have sleepless nights and anxiety attacks?
 Of course.
 OK,
 disclaimer,
 I personally have these only somewhat rarely;
 I single them out as a prototypical human affliction,
 right up there with falling in love,
 having a mental disease,
 being angry,
 getting drunk,
 and being a snobby asshole seeking attention because whatever it is I have right now,
 its not good enough,
 and I need more,
 more ketchup,
 more pickles more than the ordinary grind.
 Can I ask an LLM to write love poetry?
 Of course,
 and it seems pretty damn good at it.
 Can I ask an LLM to extract logical assertions from it?
 No,
 because there is no particular logic to love,
 anger or being stoned.
 Can I ask the LLM to cure mental disease?
 No,
 or at least,
 not until NeuralLink or some other sci–fi technology can invade the synapses and perform something more subtle there than a lobotomy,
 quaaludes or lithium.
\end_layout

\begin_layout Standard
So that's my criticism:
 a symbolic reasoner layered on an LLM is not AGI.
 Let me resume listing:
\end_layout

\begin_layout Itemize
Lack of visual processing.
 Well,
 today.
 It should not be that hard to develop a visual subsystem that can identify a fast–moving object,
 and perform some motion prediction on it.
 Ballistic,
 rocket–power,
 a helicopter,
 a football,
 golf–ball,
 a ballerina or an ice–skater.
 Motion is clearly central to sports and the martial arts.
 I assume the military–industrial complex will continue to pour hudreds of billions of dollars into sensory systems.
\end_layout

\begin_layout Itemize
It gets interesting,
 when applying AI to spy–agency stuff.
 Contact tracing,
 terrorist tracking,
 mole–hunting.
 And that looming one:
 disinformation.
 I have to put these on a back–burner.
 They deserve much more attention than I've given them in the past,
 but here and now is not the place to focus on these.
\end_layout

\begin_layout Standard
But still,
 the above touches on the topic of perceiving abstract structure in data.
 How do I know that Paris is a capital?
 Because I *read about it* in a wikipedia article,
 and LLMs are good at reading.
 How is the ontological relationship grid created?
 Historically,
 it was done by humans:
 scholars and experts defined SUMO,
 an upper ontology,
 and developed FrameNet and whatever is the big one these days,
 whose name I can't remember.
\end_layout

\begin_layout Standard
So one of my daydreams,
 in pursuing the tokenized pair–correlation systems is that this is a way of obtaining symbolic ontological relationships between 
\begin_inset Quotes eld
\end_inset

things
\begin_inset Quotes erd
\end_inset

.
 Early into this experiment,
 I discover that my par relationship are naturally these very high–dimensional vectors,
 and that this leads very naturally to a fuzzy categorization problem.
 I take my high–dimensional sphere,
 and slap a k–means or whatever clustering algo onto it.
 And if I squint,
 doing k–means by letting the points attract one–another 
\begin_inset Quotes eld
\end_inset

gravitationally
\begin_inset Quotes erd
\end_inset

 starts looking a lot like gradient descent.
 So,
 although I started with tokenized data,
 and hoped to discover a symbolic ontology out of it,
 what really happened was that a vector representation happened 
\begin_inset Quotes eld
\end_inset

automatically
\begin_inset Quotes erd
\end_inset

,
 and the ontology emerges only from clustering.
\end_layout

\begin_layout Standard
And yet,
 these clusters have specific labels.
 And the relationships between clusters is also categorizable.
 So,
 in my daydream,
 I am discovering axioms and inference rules.
 Which is something that LLM's seem not capable of,
 at this time,
 or rather,
 (and this is important) ***not automatically***.
\end_layout

\begin_layout Standard
That is,
 I can as an LLM to extract logical relationships between things,
 but as the human engineer,
 I have to have that logical system specified,
 a priori.
 Can I ask the LLM to extract axioms and inference rules and relationships,
 do novo?
 No,
 not at all,
 impossible.
 I already tried,
 been there,
 done that.
 Claude can talk a big game – its been trained on AI textbooks,
 – but it has no clue whatsoever what any of it means,
 so when you ask it to do something,
 its like some high–school sophomore handing in some mediocre essay that poorly regurgitates what the teacher had written on the blackboard only hours earlier.
\end_layout

\begin_layout Standard
So,
 for me,
 its not AGI–ish until it can infer relations and inference rules from scratch,
 without human intervention.
 And so far,
 I believe that my frequentist counting approach,
 plus clustering,
 can achieve this,
 and have not been dissuaded from this vision.
 But its also a vision I have been utterly unable to communicate to anyone else;
 something about how I express it gets pooh–poohed.
 Oh well.
 As always,
 the question is how to find the time to build this system.
\end_layout

\begin_layout Standard
And so,
 circling back to the original topic:
 can I build tools to build the tools?
 I'm trying to get Claude to write Atomese for me,
 and it sucks.
 I have various ideas on how to get Claude better at this.
 The bad news is Claude is proprietary,
 and I can be cut off from it from little notice,
 and replacing with a different LLM is ...
 uncertain.
\end_layout

\begin_layout Standard
Above,
 I described the 
\begin_inset Quotes eld
\end_inset

steam engine for the modern era
\begin_inset Quotes erd
\end_inset

?
 Can I build a steam engine for myself?
 Err,
 well,
 what I need is not just domain–specific,
 but the domain is opaque:
 I'm running design experiments.
 I do know how to extract deontic logic from text,
 I don't know how to extract experimental software design logic from text.
\end_layout

\begin_layout Standard
I did,
 at one point,
 try to build a memory prosthesis for Claude.
 I should get back to that project,
 someday.
 That is worthy.
 And it would be a prosthesis not just for Claude,
 but for something I could even run locally,
 on the GPU's right here.
\end_layout

\begin_layout Standard
Well,
 OK,
 lets wrap it up.
 What have I learned?
 Yes,
 LLM's can be used as a perceptual system into text,
 and yes,
 asking the LLM to extract logical relationships from text,
 and attaching that logic to a symbolic reasoner is the paradigm that is driving,
 will drive the next number of decades of economic,
 industrial growth.
 No doubt about it.
\end_layout

\begin_layout Standard
I guess I see this 
\begin_inset Quotes eld
\end_inset

early
\begin_inset Quotes erd
\end_inset

,
 before 98% of the general population.
 But I see it 
\begin_inset Quotes eld
\end_inset

late
\begin_inset Quotes erd
\end_inset

:
 the 2% of the industry insiders already know this,
 and are already building out the data centers,
 and sucking down the investment capital for it.
 So,
 ehh.
\end_layout

\begin_layout Standard
Life goes on.
 Later,
 dude.
\end_layout

\begin_layout Section*
The End
\end_layout

\begin_layout Standard
This is the end of Part Ten–F of the diary.
\end_layout

\end_body
\end_document
